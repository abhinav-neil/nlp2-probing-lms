{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probing Language Models for Structure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports <a id=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os, random\n",
    "import gdown\n",
    "from collections import defaultdict\n",
    "from lstm.model import RNNModel\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from conllu import parse_incr, TokenList\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, RobertaTokenizer, RobertaModel, OPTModel, AutoTokenizer\n",
    "from ete3 import Tree\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Language models <a id=\"models\"></a>\n",
    "\n",
    "### Transformer\n",
    "We will use the `transformers` library of Huggingface: https://github.com/huggingface/transformers\n",
    "\n",
    "### LSTM\n",
    "We will use the Gulordava LSTM from the Colorless Green RNNs paper: https://arxiv.org/pdf/1803.11138.pdf. The weigths are available at https://drive.google.com/file/d/19Lp3AM4NEPycp_IBgoHfLc_V456pmUom/view?usp=sharing. The original code is available at https://github.com/facebookresearch/colorlessgreenRNNs/blob/master/src/language_models/model.py. The code has been altered to only output the hidden states that we are interested in. For further experiments, have a look at the original code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# load models and tokenizers\n",
    "# gpt2 (distilgpt2)\n",
    "gpt2d_model = GPT2LMHeadModel.from_pretrained('distilgpt2')\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
    "\n",
    "# roberta\n",
    "roberta_model = RobertaModel.from_pretrained('roberta-base')\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# gpt2 (gpt2-medium)\n",
    "gpt2m_model = GPT2LMHeadModel.from_pretrained('gpt2-medium')\n",
    "gpt2m_tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
    "\n",
    "# french gpt2\n",
    "gpt2fr_model = GPT2LMHeadModel.from_pretrained(\"antoiloui/belgpt2\")\n",
    "gpt2fr_tokenizer = GPT2Tokenizer.from_pretrained(\"antoiloui/belgpt2\")\n",
    "\n",
    "# LSTM\n",
    "lstm_path = 'lstm/state_dict.pt'  # path to saved lstm model\n",
    "if not os.path.exists(lstm_path):\n",
    "    lstm_model_url = 'https://drive.google.com/u/0/uc?id=19Lp3AM4NEPycp_IBgoHfLc_V456pmUom'\n",
    "    gdown.download(lstm_model_url, lstm_path, quiet=False)\n",
    "lstm_model = RNNModel('LSTM', 50001, 650, 650, 2)\n",
    "lstm_model.load_state_dict(torch.load(lstm_path))\n",
    "# the LSTM uses a vocab dict that maps a token to an id, instead of a tokenizer\n",
    "with open('lstm/vocab.txt') as f:\n",
    "    w2i = {w.strip(): i for i, w in enumerate(f)}\n",
    "vocab = defaultdict(lambda: w2i[\"<unk>\"])\n",
    "vocab.update(w2i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PoS probing <a id=\"pos probe\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "tags": [
     "globals"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LM: gpt2fr | using sample: False | data dir: data/gpt2fr | model dir: models/gpt2fr/\n"
     ]
    }
   ],
   "source": [
    "# set global variables\n",
    "lm = gpt2fr_model  # language model\n",
    "language = 'fr'\n",
    "use_sample = False   # use a small sample of the data for faster debugging\n",
    "lm_names = {lstm_model: 'lstm', gpt2d_model: 'gpt2d', roberta_model: 'roberta', gpt2m_model: 'gpt2m', gpt2fr_model: 'gpt2fr'}\n",
    "lm_name = lm_names[lm]\n",
    "tokenizers = {'lstm': vocab, 'gpt2d': gpt_tokenizer, 'roberta': roberta_tokenizer, 'gpt2m': gpt2m_tokenizer, 'gpt2fr': gpt2fr_tokenizer}\n",
    "tokenizer = tokenizers[lm_name]\n",
    "data_dir = f'data/sample/{lm_name}' if use_sample else f'data/{lm_name}'  # path to data\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "model_dir = f'models/sample/{lm_name}/' if use_sample else f'models/{lm_name}/'  # path to models\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "print(f'LM: {lm_name} | using sample: {use_sample} | data dir: {data_dir} | model dir: {model_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Generate data for PoS probe <a id=\"pos data\"></a>\n",
    "We will use a treebank corpus for our data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 156.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "def parse_corpus(filename: str) -> List[TokenList]:\n",
    "    data_file = open(filename, encoding=\"utf-8\")\n",
    "    ud_parses = list(parse_incr(data_file))\n",
    "    \n",
    "    return ud_parses\n",
    "\n",
    "# ud_parses_sample = parse_corpus('data/sample/en_ewt-ud-train.conllu')\n",
    "\n",
    "# fetch sentence representations\n",
    "def fetch_sen_reps(ud_parses: List[TokenList], model=lm, tokenizer=tokenizer, concat=True) -> torch.Tensor:\n",
    "    '''\n",
    "    returns sentence representations (embeddings) for a list of sentences, by first tokenizing them and then passing them through the model\n",
    "    inputs:\n",
    "        ud_parses: list of sentences, each sentence is a list of tokens, each token is a dictionary (conllu format)\n",
    "        model: the language model (encoder) to use for sentence representation, either an LSTM or a transformer (GPT2)\n",
    "        tokenizer: either the GPT2 tokenizer or the LSTM vocab\n",
    "        rep_size: the size of the sentence representations (embeddings)\n",
    "    returns:\n",
    "        sent_reps: a tensor of shape (num_tokens_in_corpus, representation_size), containing the sentence representations (embeddings) for all sentences in the corpus\n",
    "    '''\n",
    "    model.eval()    # set model to evaluation mode\n",
    "    sent_reps = []\n",
    "    for sent in tqdm(ud_parses):\n",
    "        # LSTM\n",
    "        if model == lstm_model:\n",
    "            # tokenize\n",
    "            sent_tokenized = torch.tensor([tokenizer[token['form']] for token in sent if token[\"upostag\"] != \"_\"])\n",
    "            # get sentence representation\n",
    "            with torch.no_grad():\n",
    "                out_rep = model(sent_tokenized.unsqueeze(0), model.init_hidden(1)).squeeze(0)\n",
    "                \n",
    "        # transformers\n",
    "        elif model in [gpt2d_model, gpt2m_model, gpt2fr_model, roberta_model]:\n",
    "            token_ids, att_masks = [], []\n",
    "            add_space = False   # whether to add a space before the token\n",
    "            for token in sent:\n",
    "                if token[\"upostag\"] == \"_\": # skip invalid/multiword tokens\n",
    "                    continue\n",
    "                # tokenize\n",
    "                if model == roberta_model:\n",
    "                    tokenized = tokenizer.encode_plus(\" \" + token['form'] if add_space else token['form'], return_tensors='pt')\n",
    "                else:\n",
    "                    tokenized = tokenizer(\" \" + token['form'], return_tensors='pt') if add_space else tokenizer(token['form'], return_tensors='pt')\n",
    "\n",
    "                token_ids.append(tokenized['input_ids'][0])\n",
    "                att_masks.append(tokenized['attention_mask'][0])\n",
    "                # check whether to add a space before the next token\n",
    "                add_space = False if token['misc'] is not None and token['misc'].get('SpaceAfter', '') == 'No' else True\n",
    "                \n",
    "            # get sentence representation\n",
    "            with torch.no_grad():\n",
    "                if model == roberta_model:\n",
    "                    out = model(input_ids=torch.hstack(token_ids).unsqueeze(0), attention_mask=torch.hstack(att_masks).unsqueeze(0), token_type_ids=None, output_hidden_states=True).last_hidden_state.squeeze(0)\n",
    "                else:\n",
    "                    out = model(input_ids=torch.hstack(token_ids), attention_mask=torch.hstack(att_masks), output_hidden_states=True).hidden_states[-1]\n",
    "\n",
    "            # average over parts belonging to the same token\n",
    "            out_rep = torch.zeros(len(token_ids), out.shape[-1])\n",
    "            num_sub_tokens = 0\n",
    "            for i in range(out_rep.shape[0]):\n",
    "                out_rep[i] = out[i + num_sub_tokens: i + num_sub_tokens + len(token_ids[i])].mean(0)\n",
    "                num_sub_tokens += len(token_ids[i]) - 1\n",
    "                \n",
    "        else :\n",
    "            raise ValueError('model should be one of: lstm_model, gpt2d_model, gpt2m_model, gpt2fr_model, roberta_model')       \n",
    "        sent_reps += out_rep if concat else [out_rep]\n",
    "    \n",
    "    # stack token representations of entire corpus\n",
    "    if concat:\n",
    "        sent_reps = torch.vstack(sent_reps)\n",
    "    \n",
    "    return sent_reps\n",
    "\n",
    "# test fetch_sen_reps\n",
    "def error_msg(model_name, gold_embs, embs, i2w):\n",
    "    with open(f'{model_name}_tokens1.pickle', 'rb') as f:\n",
    "        sen_tokens = pickle.load(f)\n",
    "        \n",
    "    diff = torch.abs(embs - gold_embs)\n",
    "    max_diff = torch.max(diff)\n",
    "    avg_diff = torch.mean(diff)\n",
    "    \n",
    "    print(f\"{model_name} embeddings don't match!\")\n",
    "    print(f\"Max diff.: {max_diff:.4f}\\nMean diff. {avg_diff:.4f}\")\n",
    "\n",
    "    print(\"\\nCheck if your tokenization matches with the original tokenization:\")\n",
    "    for idx in sen_tokens.squeeze():\n",
    "        if isinstance(i2w, list):\n",
    "            token = i2w[idx]\n",
    "        else:\n",
    "            token = i2w.convert_ids_to_tokens(idx.item())\n",
    "        print(f\"{idx:<6} {token}\")\n",
    "\n",
    "\n",
    "def assert_sen_reps(model, tokenizer, lstm, vocab):\n",
    "    with open('distilgpt2_emb1.pickle', 'rb') as f:\n",
    "        distilgpt2_emb1 = pickle.load(f)\n",
    "        \n",
    "    with open('lstm_emb1.pickle', 'rb') as f:\n",
    "        lstm_emb1 = pickle.load(f)\n",
    "    \n",
    "    corpus = parse_corpus('data/sample/en_ewt-ud-train.conllu')[:1]\n",
    "    \n",
    "    own_distilgpt2_emb1 = fetch_sen_reps(corpus, model, tokenizer)\n",
    "    own_lstm_emb1 = fetch_sen_reps(corpus, lstm, vocab)\n",
    "    \n",
    "    assert distilgpt2_emb1.shape == own_distilgpt2_emb1.shape, \\\n",
    "        f\"Distilgpt2 shape mismatch: {distilgpt2_emb1.shape} (gold) vs. {own_distilgpt2_emb1.shape} (yours)\"\n",
    "    assert lstm_emb1.shape == own_lstm_emb1.shape, \\\n",
    "        f\"LSTM shape mismatch: {lstm_emb1.shape} (gold) vs. {own_lstm_emb1.shape} (yours)\"\n",
    "\n",
    "    if not torch.allclose(distilgpt2_emb1, own_distilgpt2_emb1, rtol=1e-3, atol=1e-3):\n",
    "        error_msg(\"distilgpt2\", distilgpt2_emb1, own_distilgpt2_emb1, tokenizer)\n",
    "    if not torch.allclose(lstm_emb1, own_lstm_emb1, rtol=1e-3, atol=1e-3):\n",
    "        error_msg(\"lstm\", lstm_emb1, own_lstm_emb1, list(vocab.keys()))\n",
    "\n",
    "\n",
    "assert_sen_reps(gpt2d_model, gpt_tokenizer, lstm_model, vocab)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting PoS labels\n",
    "Next, we should define a function that extracts the corresponding POS labels for each activation. These labels will be transformed to a tensor containing the label index for each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch POS tags\n",
    "def fetch_pos_tags(ud_parses: List[TokenList], pos_vocab: Optional[Dict[str, int]] = None) -> Tuple[torch.Tensor, Dict[str, int]]:\n",
    "\t'''\n",
    "\treturn the POS tags for all tokens in the corpus\n",
    "\tinputs:\n",
    "\t\tud_parses: list of sentences, each sentence is a list of tokens, each token is a dictionary (conllu format)\n",
    "\t\tpos_vocab: a dictionary mapping POS tags to integers (optional)\n",
    "\treturns:\n",
    "\t\tpos_tags: a tensor of shape (num_tokens_in_corpus,) containing the POS tags for all tokens in the corpus\n",
    "\t'''\n",
    "\tif pos_vocab is None:\n",
    "\t\tpos_vocab = defaultdict(int)\n",
    "\t\tfor sent in ud_parses:\n",
    "\t\t\tfor token in sent:\n",
    "\t\t\t\t# add new POS tags to vocab\n",
    "\t\t\t\tif token[\"upostag\"] not in pos_vocab and token[\"upostag\"] != \"_\":\n",
    "\t\t\t\t\tpos_vocab[token[\"upostag\"]] = len(pos_vocab)\n",
    "\n",
    "\tpos_tags = [torch.tensor(pos_vocab[token[\"upostag\"]])\n",
    "\t\t\t\t\t\t\t for sent in ud_parses for token in sent if token[\"upostag\"] != \"_\"]\n",
    "\tpos_tags = torch.vstack(pos_tags).squeeze()\n",
    "\n",
    "\treturn pos_tags, pos_vocab\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge representations & PoS tags\n",
    "We merge sentence representations (features) and PoS tags (labels) to create dataloaders for the probe. We pass the `train_vocab` to the data creation of the `dev` and `test` data is that we want to use the same label vocabulary across the different train/val/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating train/val/test data...\n",
      "parsing corpus...\n",
      "fetching sentence representations using gpt2fr...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1476/1476 [01:02<00:00, 23.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching POS tags...\n",
      "parsing corpus...\n",
      "fetching sentence representations using gpt2fr...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1476/1476 [01:01<00:00, 23.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching POS tags...\n",
      "parsing corpus...\n",
      "fetching sentence representations using gpt2fr...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 416/416 [00:17<00:00, 23.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching POS tags...\n",
      "size of train data: 35704 | size of val data: 35704 | size of test data: 10015\n",
      "CPU times: user 36min 57s, sys: 1.34 s, total: 36min 59s\n",
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create 2 tensors for a .conllu file: 1 containing the token representations, and 1 containing the (tokenized) pos_tags\n",
    "def create_data(filename: str, lm, pos_vocab=None):\n",
    "    print('parsing corpus...')\n",
    "    ud_parses = parse_corpus(filename)\n",
    "    print(f'fetching sentence representations using {lm_name}...')\n",
    "    sen_reps = fetch_sen_reps(ud_parses, lm)\n",
    "    print('fetching POS tags...')\n",
    "    pos_tags, pos_vocab = fetch_pos_tags(ud_parses, pos_vocab=pos_vocab)    \n",
    "    return sen_reps, pos_tags, pos_vocab\n",
    "\n",
    "# create datasets and dataloaders\n",
    "# define a custom PyTorch dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "# create train/val/test data\n",
    "# path to the .conllu files\n",
    "if language == 'en':\n",
    "    train_path = 'data/sample/en_ewt-ud-train.conllu' if use_sample else 'data/en_ewt-ud-train.conllu'\n",
    "    val_path = 'data/sample/en_ewt-ud-val.conllu' if use_sample else 'data/en_ewt-ud-dev.conllu'\n",
    "    test_path = 'data/sample/en_ewt-ud-test.conllu' if use_sample else 'data/en_ewt-ud-test.conllu'\n",
    "elif language == 'fr':\n",
    "    train_path = 'data/fr_gsd-ud-dev.conllu'\n",
    "    val_path = 'data/fr_gsd-ud-dev.conllu'\n",
    "    test_path = 'data/fr_gsd-ud-test.conllu'\n",
    "    \n",
    "# create or load the data\n",
    "# try:\n",
    "#     train_x_pos, train_y_pos, train_vocab_pos = torch.load(f'{data_dir}/train_x_pos.pt'), torch.load(f'{data_dir}/train_y_pos.pt'), torch.load(f'{data_dir}/train_vocab_pos.pt')\n",
    "# except FileNotFoundError:\n",
    "#     print('creating train data...')\n",
    "#     train_x_pos, train_y_pos, train_vocab_pos = create_data(train_path, lm)\n",
    "#     torch.save(train_x_pos, f'{data_dir}/train_x_pos.pt')\n",
    "#     torch.save(train_y_pos, f'{data_dir}/train_y_pos.pt')\n",
    "#     torch.save(train_vocab_pos, f'{data_dir}/train_vocab_pos.pt')\n",
    "# try:\n",
    "#     val_x_pos, val_y_pos = torch.load(f'{data_dir}/val_x_pos.pt'), torch.load(f'{data_dir}/val_y_pos.pt')\n",
    "# except FileNotFoundError:\n",
    "#     print('creating val data...')\n",
    "#     val_x_pos, val_y_pos, _ = create_data(val_path, lm, pos_vocab=train_vocab_pos)\n",
    "#     torch.save(val_x_pos, f'{data_dir}/val_x_pos.pt')\n",
    "#     torch.save(val_y_pos, f'{data_dir}/val_y_pos.pt')\n",
    "# try:\n",
    "#     test_x_pos, test_y_pos = torch.load(f'{data_dir}/test_x_pos.pt'), torch.load(f'{data_dir}/test_y_pos.pt')\n",
    "# except FileNotFoundError:\n",
    "#     print('creating test data...')\n",
    "#     test_x_pos, test_y_pos, _ = create_data(test_path, lm, pos_vocab=train_vocab_pos)\n",
    "#     torch.save(test_x_pos, f'{data_dir}/test_x_pos.pt')\n",
    "#     torch.save(test_y_pos, f'{data_dir}/test_y_pos.pt')\n",
    "    \n",
    "# create dataloaders\n",
    "# train_data_pos = MyDataset(train_x_pos, train_y_pos)\n",
    "# val_data_pos = MyDataset(val_x_pos, val_y_pos)\n",
    "# test_data_pos = MyDataset(test_x_pos, test_y_pos)\n",
    "\n",
    "try:\n",
    "    train_data_pos = torch.load(f'{data_dir}/train_data_pos.pt')\n",
    "    val_data_pos = torch.load(f'{data_dir}/val_data_pos.pt')\n",
    "    test_data_pos = torch.load(f'{data_dir}/test_data_pos.pt')\n",
    "except FileNotFoundError:\n",
    "    print('creating train/val/test data...')\n",
    "    train_x_pos, train_y_pos, train_vocab_pos = create_data(train_path, lm)\n",
    "    val_x_pos, val_y_pos, _ = create_data(val_path, lm, pos_vocab=train_vocab_pos)\n",
    "    test_x_pos, test_y_pos, _ = create_data(test_path, lm, pos_vocab=train_vocab_pos)\n",
    "    train_data_pos = MyDataset(train_x_pos, train_y_pos)\n",
    "    val_data_pos = MyDataset(val_x_pos, val_y_pos)\n",
    "    test_data_pos = MyDataset(test_x_pos, test_y_pos)\n",
    "    torch.save(train_vocab_pos, f'{data_dir}/train_vocab_pos.pt')\n",
    "    torch.save(train_data_pos, f'{data_dir}/train_data_pos.pt')\n",
    "    torch.save(val_data_pos, f'{data_dir}/val_data_pos.pt')\n",
    "    torch.save(test_data_pos, f'{data_dir}/test_data_pos.pt')\n",
    "    \n",
    "print(f'size of train data: {len(train_data_pos)} | size of val data: {len(val_data_pos)} | size of test data: {len(test_data_pos)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train & test PoS probe <a name=\"dc\"></a>\n",
    "We will train a PoS probe using simple linear model. Refer \"Designing and Interpreting Probes with Control Tasks\" by Hewitt and Liang (esp. Sec. 3.2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic classifier/probe\n",
    "# class to store training parameters\n",
    "class TrainingParams:\n",
    "    def __init__(self, lr=1e-3, batch_size=256, num_epochs=1000, patience=10):\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.patience = patience\n",
    "        \n",
    "def set_seed(seed):\n",
    "    # Set seed for random, numpy, PyTorch\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "        \n",
    "def train_pos_probe(model, train_data, val_data, params, seed=42, print_every=10):\n",
    "    set_seed(seed)  # set seed for reproducibility\n",
    "    # create dataloaders\n",
    "    train_loader = DataLoader(train_data, batch_size=params.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=params.batch_size, shuffle=False)\n",
    "    # define loss and optimizer\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=params.lr)\n",
    "    val_losses, val_accs = [], []\n",
    "\n",
    "    # training/val loop\n",
    "    for epoch in range(params.num_epochs):\n",
    "        # train\n",
    "        model.train()\n",
    "        for train_x, train_y in train_loader:\n",
    "            out = model(train_x)\n",
    "            loss = criterion(out, train_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            \n",
    "        # validate\n",
    "        model.eval()\n",
    "        val_losses_epoch, val_accs_epoch = [], []\n",
    "        for val_x, val_y in val_loader:\n",
    "            with torch.no_grad():\n",
    "                out = model(val_x)\n",
    "                loss = criterion(out, val_y)\n",
    "                val_losses_epoch.append(loss.item())\n",
    "                preds_val = torch.argmax(out, dim=1)\n",
    "                acc = (preds_val == val_y).sum().item() / len(val_y)\n",
    "                val_accs_epoch.append(acc)\n",
    "                \n",
    "        val_loss_epoch = np.mean(val_losses_epoch)\n",
    "        val_acc_epoch = np.mean(val_accs_epoch)\n",
    "        val_losses.append(val_loss_epoch)\n",
    "        val_accs.append(val_acc_epoch)\n",
    "        \n",
    "        if epoch % print_every == 0:\n",
    "            print(f'epoch: {epoch} | val loss: {val_loss_epoch:.3f} | val acc: {val_acc_epoch:.3f}')\n",
    "        \n",
    "        # early stopping\n",
    "        if epoch >= params.patience and val_loss_epoch >= val_losses[-params.patience]:\n",
    "            print(f'val loss did not improve for {params.patience} epochs, stopping training')\n",
    "            break\n",
    "        \n",
    "    # save model\n",
    "    # model_path = f'{model_dir}/linear_pos_probe.pt'\n",
    "    # torch.save(model, model_path)\n",
    "        \n",
    "    return model, val_losses, val_accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy of linear pos probe using gpt2fr embeddings is 0.921\n"
     ]
    }
   ],
   "source": [
    "# train pos probe\n",
    "pos_probe_type = 'linear' # type of PoS probe, either 'linear' or 'nonlinear'\n",
    "try:\n",
    "    pos_probe_model = torch.load(f'{model_dir}/{pos_probe_type}_pos_probe.pt')\n",
    "except FileNotFoundError:\n",
    "    params = TrainingParams()\n",
    "    if pos_probe_type == 'linear':\n",
    "        # single linear layer with input_dim = embedding_dim and output_dim = len(pos_vocab), no activation\n",
    "        pos_probe_model = nn.Linear(train_data_pos.x.shape[1], len(train_vocab_pos))\n",
    "    elif pos_probe_type == 'nonlinear':\n",
    "        # two linear layers of shape (embedding_dim, hidden_dim) and (hidden_dim, len(pos_vocab)), with ReLU activation in between\n",
    "        hidden_dim = 100\n",
    "        pos_probe_model = nn.Sequential(\n",
    "            nn.Linear(train_data_pos.x.shape[1], hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, len(train_vocab_pos)))\n",
    "    else:\n",
    "        raise ValueError('pos_probe_type must be linear or nonlinear')\n",
    "    \n",
    "    print(f'training {pos_probe_type} pos probe with {lm_name} embeddings...')\n",
    "    pos_probe_model, _, _ = train_pos_probe(pos_probe_model, train_data_pos, val_data_pos, params)\n",
    "    torch.save(pos_probe_model, f'{model_dir}/{pos_probe_type}_pos_probe.pt')\n",
    "\n",
    "# test\n",
    "out_test = pos_probe_model(test_data_pos.x)\n",
    "preds_test_pos = torch.argmax(out_test, dim=1)\n",
    "test_acc_pos = (preds_test_pos == test_data_pos.y).sum().item() / len(test_data_pos.y)\n",
    "print(f'test accuracy of {pos_probe_type} pos probe using {lm_name} embeddings is {test_acc_pos:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg PoS accuracy of 1st 5 sentences in test set using gpt2fr embeddings: [0.9310344827586207, 1.0, 0.9523809523809523, 0.9302325581395349, 0.8947368421052632]\n"
     ]
    }
   ],
   "source": [
    "# compute avg PoS accuracy per sentence in test set\n",
    "def get_pos_acc_sent(preds_pos, y_pos):\n",
    "    '''\n",
    "    Compute average PoS accuracy per sentence in test set\n",
    "    Inputs:\n",
    "        ud_parses: list of lists of UD parse trees\n",
    "        preds_pos: predicted PoS tags\n",
    "        y_pos: true PoS tags\n",
    "    Returns:\n",
    "        accs_pos_sent: list of average PoS accuracies per sentence\n",
    "    '''\n",
    "    token_count = 0\n",
    "    accs_pos_sent = []\n",
    "    for sent in test_ud_parses:\n",
    "        acc_pos_sent = (preds_pos[token_count:token_count+len(sent)] == y_pos[token_count:token_count+len(sent)]).sum().item() / len(sent)\n",
    "        accs_pos_sent.append(acc_pos_sent)\n",
    "        token_count += len(sent)\n",
    "    return accs_pos_sent\n",
    "\n",
    "test_ud_parses = parse_corpus(test_path)\n",
    "test_accs_pos_sent = get_pos_acc_sent(preds_test_pos, test_y_pos)\n",
    "print(f'avg PoS accuracy of 1st 5 sentences in test set using {lm_name} embeddings: {test_accs_pos_sent[:5]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Control tasks for PoS probe <a name=\"control-tasks-pos\"></a>\n",
    "We will train a control task to check if the probe is actually probing the linguistic information. We will use the same model as the probe, but we will train it to predict a random label for each input. If the probe is actually probing the linguistic information, it should perform better than the control task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1476/1476 [00:00<00:00, 18007.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training control probe with gpt2fr embeddings...\n",
      "epoch: 0 | val loss: 1.584 | val acc: 0.532\n",
      "epoch: 10 | val loss: 1.274 | val acc: 0.618\n",
      "epoch: 20 | val loss: 1.258 | val acc: 0.626\n",
      "epoch: 30 | val loss: 1.257 | val acc: 0.627\n",
      "val loss did not improve for 10 epochs, stopping training\n",
      "test accuracy of control probe using gpt2fr embeddings is 0.565\n"
     ]
    }
   ],
   "source": [
    "def fetch_pos_control_labels(corpus_path: str, control_vocab=None,  len_pos_vocab: int=None) -> torch.Tensor:\n",
    "\t'''\n",
    "\tGenerate control task labels for each token in the corpus.\n",
    "\tInputs:\n",
    "\t\tud_parses: list of sentences, each sentence is a list of tokens, each token is a dictionary (conllu format)\n",
    "\t\tlen_pos_vocab: length of the pos_vocab dictionary\n",
    "\t\tcontrol_vocab: a dictionary mapping tokens to control labels (optional)\n",
    "\tReturns:\n",
    "\t\tcontrol_labels: a tensor of shape (num_tokens_in_corpus,) containing the control task labels for all tokens in the corpus\n",
    "\t\tcontrol_vocab: a dictionary mapping tokens to control labels\n",
    "\t'''\n",
    "\tud_parses = parse_corpus(corpus_path)\n",
    "\tif not control_vocab:\n",
    "\t\tcontrol_vocab = defaultdict(int)\n",
    "\t\tfor sent in tqdm(ud_parses):\n",
    "\t\t\tfor token in sent:\n",
    "\t\t\t\tif token[\"upostag\"] == \"_\":\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tif token['form'] not in control_vocab:\n",
    "\t\t\t\t\tcontrol_vocab[token['form']] = np.random.randint(len_pos_vocab)\n",
    "\n",
    "\tcontrol_labels = [torch.tensor(control_vocab[token['form']]) for sent in ud_parses for token in sent if token[\"upostag\"] != \"_\"]\n",
    "\tcontrol_labels = torch.vstack(control_labels).squeeze()\n",
    "\t\n",
    "\treturn control_labels, control_vocab\n",
    "\n",
    "# create data for control task\n",
    "train_y_pos_control, train_vocab_pos_control = fetch_control_labels(train_path, None, len(train_vocab_pos))\n",
    "val_y_pos_control, _ = fetch_pos_control_labels(val_path, train_vocab_pos_control)\n",
    "test_y_pos_control, _ = fetch_pos_control_labels(test_path, train_vocab_pos_control)\n",
    "train_data_pos_control = MyDataset(train_data_pos.x, train_y_pos_control)\n",
    "val_data_pos_control = MyDataset(val_data_pos.x, val_y_pos_control)\n",
    "test_data_pos_control = MyDataset(test_data_pos.x, test_y_pos_control)\n",
    "\n",
    "# train control probe\n",
    "try:\n",
    "\tpos_control_probe_model = torch.load(f'{model_dir}/pos_control_probe.pt')\n",
    "except FileNotFoundError:\n",
    "\tparams = TrainingParams()\n",
    "\t# single linear layer with input_dim = embedding_dim and output_dim = len(pos_vocab), no activation\n",
    "\tpos_control_probe_model = nn.Linear(train_data_pos.x.shape[1], len(train_vocab_pos_control))\n",
    "\tprint(f'training control probe with {lm_name} embeddings...')\n",
    "\tpos_control_probe_model, _, _ = train_pos_probe(pos_control_probe_model, train_data_pos_control, val_data_pos_control, params)\n",
    "\ttorch.save(pos_control_probe_model, f'{model_dir}/pos_control_probe.pt')\n",
    "\n",
    "# test\n",
    "out_test = pos_control_probe_model(test_data_pos.x)\n",
    "preds_test_pos_control = torch.argmax(out_test, dim=1)\n",
    "test_acc_pos_control = (preds_test_pos_control == test_y_pos_control).sum().item() / len(test_y_pos_control)\n",
    "print(f'test accuracy of control probe using {lm_name} embeddings is {test_acc_pos_control:.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Structural probing <a name=\"structural probe\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Trees <a name=\"trees\"></a>\n",
    "\n",
    "For our gold labels, we need to recover the node distances from our parse tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to tranform trees\n",
    "def rec_tokentree_to_nltk(tokentree):\n",
    "    token = tokentree.token[\"form\"]\n",
    "    tree_str = f\"({token} {' '.join(rec_tokentree_to_nltk(t) for t in tokentree.children)})\"\n",
    "    return tree_str\n",
    "\n",
    "def tokentree_to_nltk(tokentree):\n",
    "    from nltk import Tree as NLTKTree\n",
    "    tree_str = rec_tokentree_to_nltk(tokentree)\n",
    "    return NLTKTree.fromstring(tree_str)\n",
    "\n",
    "class FancyTree(Tree):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, format=1, **kwargs)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.get_ascii(show_internal=True)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "# transform your conllu tree to an ete3.Tree, for better visualisation\n",
    "def rec_tokentree_to_ete(tokentree):\n",
    "    idx = str(tokentree.token[\"id\"])\n",
    "    children = tokentree.children\n",
    "    if children:\n",
    "        return f\"({','.join(rec_tokentree_to_ete(t) for t in children)}){idx}\"\n",
    "    else:\n",
    "        return idx\n",
    "    \n",
    "def tokentree_to_ete(tokentree):\n",
    "    newick_str = rec_tokentree_to_ete(tokentree)\n",
    "    return FancyTree(f\"{newick_str};\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing gold distances, MST & UUAS scores\n",
    "\n",
    "We label a token by its token id (converted to a string). Based on these id's we are going to retrieve the node distances. Uing the gold distances, we can compute the **minimum spanning tree (MST)**. We can then compute the Undirected Unlabeled Attachment Score (UUAS), which is expressed as:\n",
    "\n",
    "$$\\frac{\\text{number of predicted edges that are an edge in the gold parse tree}}{\\text{number of edges in the gold parse tree}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gold_distances(corpus):\n",
    "    '''Create a list of gold distances for each sentence in the corpus.'''\n",
    "    all_distances = []\n",
    "\n",
    "    for item in tqdm(corpus):\n",
    "        tokentree = item.to_tree()\n",
    "        ete_tree = tokentree_to_ete(tokentree)\n",
    "\n",
    "        sen_len = len(ete_tree.search_nodes())\n",
    "        distances = torch.zeros((sen_len, sen_len))\n",
    "\n",
    "        for node1 in ete_tree.search_nodes():\n",
    "            for node2 in ete_tree.search_nodes():\n",
    "                distances[int(node1.name)-1][int(node2.name)-1] = node1.get_distance(node2)\n",
    "\n",
    "        all_distances.append(distances)\n",
    "\n",
    "    return all_distances\n",
    "\n",
    "def create_mst(distances):\n",
    "    '''Create a minimum spanning tree from a distance matrix.'''\n",
    "    distances = torch.triu(distances).detach().numpy()\n",
    "    mst = minimum_spanning_tree(distances).toarray()\n",
    "    mst[mst>0] = 1.\n",
    "    \n",
    "    return mst\n",
    "\n",
    "# viz ete tree, gold distances, mst\n",
    "# item = corpus[5]\n",
    "# tokentree = item.to_tree()\n",
    "# ete3_tree = tokentree_to_ete(tokentree)\n",
    "# print(ete3_tree, '\\n')\n",
    "\n",
    "# gold_distance = create_gold_distances(corpus[5:6])[0]\n",
    "# print(gold_distance, '\\n')\n",
    "\n",
    "# mst = create_mst(gold_distance)\n",
    "# print(mst)\n",
    "\n",
    "def get_edges(mst):\n",
    "    '''Retrieve the edges of a minimum spanning tree.\n",
    "    Inputs: mst: np.array of shape (n, n)\n",
    "                 a minimum spanning tree of a sentence\n",
    "    Outputs: edges: set of tuples\n",
    "                the edges of the minimum spanning tree\n",
    "            '''\n",
    "    edges = np.nonzero(mst)\n",
    "    edges = list(zip(edges[0], edges[1]))\n",
    "    edges = set(map(lambda x: tuple(sorted(x)), edges))\n",
    "    return edges\n",
    "\n",
    "\n",
    "def calc_uuas(pred_distances, gold_distances):  \n",
    "    '''\n",
    "    Compute UUAS score for a pair of gold and predicted distances of a sentence.\n",
    "    '''\n",
    "    uuas_batch = []\n",
    "    for i in range(len(gold_distances)):\n",
    "        l = max(torch.nonzero(gold_distances[i] != -1, as_tuple=True)[0]) + 1\n",
    "        pred_mst = create_mst(pred_distances[i][:l, :l])\n",
    "        gold_mst = create_mst(gold_distances[i][:l, :l])\n",
    "        pred_edges = get_edges(pred_mst)\n",
    "        gold_edges = get_edges(gold_mst)\n",
    "        uuas_sent = len(pred_edges.intersection(gold_edges)) / len(gold_edges) if len(gold_edges) > 0 else -1\n",
    "        uuas_batch.append(uuas_sent)\n",
    "\n",
    "    return uuas_batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Define structural probe class & L1 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structural probe class (from John Hewitt)\n",
    "class StructuralProbe(nn.Module):\n",
    "    \"\"\" Computes squared L2 distance after projection by a matrix.\n",
    "    For a batch of sentences, computes all n^2 pairs of distances\n",
    "    for each sentence in the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_dim, rank, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.probe_rank = rank\n",
    "        self.model_dim = model_dim\n",
    "        \n",
    "        self.proj = nn.Parameter(data = torch.zeros(self.model_dim, self.probe_rank))\n",
    "        \n",
    "        nn.init.uniform_(self.proj, -0.05, 0.05)\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\" Computes all n^2 pairs of distances after projection\n",
    "        for each sentence in a batch.\n",
    "        Note that due to padding, some distances will be non-zero for pads.\n",
    "        Computes (B(h_i-h_j))^T(B(h_i-h_j)) for all i,j\n",
    "        Args:\n",
    "          batch: a batch of word representations of the shape\n",
    "            (batch_size, max_seq_len, representation_dim)\n",
    "        Returns:\n",
    "          A tensor of distances of shape (batch_size, max_seq_len, max_seq_len)\n",
    "        \"\"\"\n",
    "        transformed = torch.matmul(batch, self.proj)\n",
    "        \n",
    "        batchlen, seqlen, rank = transformed.size()\n",
    "        \n",
    "        transformed = transformed.unsqueeze(2)\n",
    "        transformed = transformed.expand(-1, -1, seqlen, -1)\n",
    "        transposed = transformed.transpose(1,2)\n",
    "        \n",
    "        diffs = transformed - transposed\n",
    "        \n",
    "        squared_diffs = diffs.pow(2)\n",
    "        squared_distances = torch.sum(squared_diffs, -1)\n",
    "\n",
    "        return squared_distances\n",
    "\n",
    "    \n",
    "class L1DistanceLoss(nn.Module):\n",
    "    \"\"\"Custom L1 loss for distance matrices.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, predictions, label_batch, length_batch):\n",
    "        \"\"\" Computes L1 loss on distance matrices.\n",
    "        Ignores all entries where label_batch=-1\n",
    "        Normalizes first within sentences (by dividing by the square of the sentence length)\n",
    "        and then across the batch.\n",
    "        Args:\n",
    "          predictions: A pytorch batch of predicted distances\n",
    "          label_batch: A pytorch batch of true distances\n",
    "          length_batch: A pytorch batch of sentence lengths\n",
    "        Returns:\n",
    "          A tuple of:\n",
    "            batch_loss: average loss in the batch\n",
    "            total_sents: number of sentences in the batch\n",
    "        \"\"\"\n",
    "        labels_1s = (label_batch != -1).float()\n",
    "        predictions_masked = predictions * labels_1s\n",
    "        labels_masked = label_batch * labels_1s\n",
    "        total_sents = torch.sum((length_batch != 0)).float()\n",
    "        squared_lengths = length_batch.pow(2).float()\n",
    "\n",
    "        if total_sents > 0:\n",
    "            loss_per_sent = torch.sum(torch.abs(predictions_masked - labels_masked), dim=(1,2))\n",
    "            normalized_loss_per_sent = loss_per_sent / squared_lengths\n",
    "            batch_loss = torch.sum(normalized_loss_per_sent) / total_sents\n",
    "        \n",
    "        else:\n",
    "            batch_loss = torch.tensor(0.0)\n",
    "        \n",
    "        return batch_loss, total_sents\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Create data for structural probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating data for structural probe...\n",
      "train\n",
      "parsing corpus...\n",
      "fetching sentence representations using gpt2fr embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1476/1476 [00:59<00:00, 24.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing gold distances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1476/1476 [00:41<00:00, 35.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "parsing corpus...\n",
      "fetching sentence representations using gpt2fr embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1476/1476 [01:02<00:00, 23.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing gold distances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1476/1476 [00:41<00:00, 35.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "parsing corpus...\n",
      "fetching sentence representations using gpt2fr embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 416/416 [00:17<00:00, 23.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing gold distances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 416/416 [00:11<00:00, 35.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train set: 1476 | size of val set: 1476 | size of test set: 416\n"
     ]
    }
   ],
   "source": [
    "def init_corpus(path, model, concat=False, cutoff=None):\n",
    "    \"\"\" Initialises the data of a corpus.\n",
    "    \n",
    "    Inputs:\n",
    "        path : str\n",
    "            Path to corpus location\n",
    "        model: language model to encode sentences, either LSTM or GPT2\n",
    "        concat : bool, optional\n",
    "            Optional toggle to concatenate all the tensors\n",
    "            returned by `fetch_sen_reps`.\n",
    "        cutoff : int, optional\n",
    "            Optional integer to \"cutoff\" the data in the corpus.\n",
    "            This allows only a subset to be used, alleviating \n",
    "            memory usage.\n",
    "    Returns:\n",
    "        embs : torch.Tensor \n",
    "            embeddings tensor of shape (num_tokens_in_corpus, model_dim)\n",
    "        gold_distances : torch.Tensor \n",
    "            gold distances tensor of shape (num_sentences_in_corpus, max_sentence_length, max_sentence_length)\n",
    "    \"\"\"\n",
    "    print('parsing corpus...')\n",
    "    corpus = parse_corpus(path)[:cutoff]\n",
    "    print(f'fetching sentence representations using {lm_name} embeddings...')\n",
    "    embs = fetch_sen_reps(corpus, model, tokenizer, concat=concat)    \n",
    "    print('computing gold distances...')\n",
    "    gold_distances = create_gold_distances(corpus)\n",
    "    \n",
    "    return embs, gold_distances\n",
    "\n",
    "# create data for structural probe\n",
    "try:\n",
    "    train_data_str = torch.load(f'{data_dir}/train_data_str.pt')\n",
    "    val_data_str = torch.load(f'{data_dir}/val_data_str.pt')\n",
    "    test_data_str = torch.load(f'{data_dir}/test_data_str.pt')\n",
    "except FileNotFoundError:\n",
    "    print('creating data for structural probe...')\n",
    "    print('train')\n",
    "    train_x_str, train_y_str = init_corpus(train_path, lm)\n",
    "    train_data_str = MyDataset(train_x_str, train_y_str)\n",
    "    print('val')\n",
    "    val_x_str, val_y_str = init_corpus(val_path, lm)\n",
    "    val_data_str = MyDataset(val_x_str, val_y_str)\n",
    "    print('test')\n",
    "    test_x_str, test_y_str = init_corpus(test_path, lm)\n",
    "    test_data_str = MyDataset(test_x_str, test_y_str)\n",
    "    torch.save(train_data_str, f'{data_dir}/train_data_str.pt')\n",
    "    torch.save(val_data_str, f'{data_dir}/val_data_str.pt')\n",
    "    torch.save(test_data_str, f'{data_dir}/test_data_str.pt')\n",
    "\n",
    "print(f'size of train set: {len(train_data_str)} | size of val set: {len(val_data_str)} | size of test set: {len(test_data_str)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Train & test structural probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate structural probe\n",
    "def evaluate_probe(model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    uuas = []\n",
    "    with torch.no_grad():\n",
    "      for x, gold_distances, length in dataloader:\n",
    "          preds = model(x)\n",
    "          loss += loss_fn(preds, gold_distances, length)[0]\n",
    "          uuas += calc_uuas(preds, gold_distances)\n",
    "    loss /= len(dataloader)\n",
    "    # take mean of uuas across batches where uuas != -1\n",
    "    uuas_avg = sum([x for x in uuas if x != -1])/len([x for x in uuas if x != -1])\n",
    "\n",
    "    return loss, uuas_avg, uuas\n",
    "\n",
    "def pad_collate_fn(batch):\n",
    "    max_length = max([len(x[1]) for x in batch])\n",
    "    out_labels = torch.full((len(batch), max_length, max_length), -1)\n",
    "    out_lengths = torch.zeros(len(batch))\n",
    "    for i, x in enumerate(batch):\n",
    "      out_labels[i, :x[1].shape[0], :x[1].shape[1]] = x[1]\n",
    "      out_lengths[i] = x[1].shape[0]\n",
    "      if len(x[0].shape) == 1:\n",
    "        batch[i] = (x[0].unsqueeze(0), x[1])\n",
    "    return torch.nn.utils.rnn.pad_sequence(list(map(lambda x: x[0].detach(), batch)), batch_first = True, padding_value=-1), out_labels, out_lengths\n",
    "\n",
    "def train_structural_probe(model, train_data, val_data, params, seed=42, print_every=10):\n",
    "    # create dataloaders\n",
    "    set_seed(seed)  # set seed for reproducibility\n",
    "    train_loader = DataLoader(train_data, batch_size=params.batch_size, shuffle=True, collate_fn=pad_collate_fn)\n",
    "    val_loader = DataLoader(val_data, batch_size=params.batch_size, shuffle=False, collate_fn=pad_collate_fn)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=params.lr)\n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1)\n",
    "    criterion =  L1DistanceLoss()\n",
    "    val_losses, val_uuas = [], []\n",
    "\n",
    "    # training/val loop\n",
    "    print(f'training structural probe with {lm_name} embeddings...')\n",
    "    for epoch in range(params.num_epochs):\n",
    "        # train\n",
    "        model.train()\n",
    "        for train_x, gold_distances, lengths in train_loader:\n",
    "            out = model(train_x)\n",
    "            loss = criterion(out, gold_distances, lengths)[0]\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            \n",
    "        # val\n",
    "        val_loss_epoch, val_uuas_epoch, _ = evaluate_probe(model, val_loader, criterion)\n",
    "        # scheduler.step(val_loss_epoch)\n",
    "        val_losses.append(val_loss_epoch)\n",
    "        val_uuas.append(val_uuas_epoch)\n",
    "        \n",
    "        if epoch % print_every == 0:\n",
    "            print(f'epoch: {epoch} | val loss: {val_loss_epoch:.3f} | val uuas: {val_uuas_epoch:.3f}')\n",
    "        \n",
    "        # early stopping\n",
    "        if epoch >= params.patience and val_loss_epoch >= val_losses[-params.patience]:\n",
    "            print(f'val loss did not improve for {params.patience} epochs, stopping training')\n",
    "            break\n",
    "        \n",
    "    return model, val_losses, val_uuas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training structural probe with gpt2fr embeddings...\n",
      "epoch: 0 | val loss: 74.428 | val uuas: 0.179\n",
      "epoch: 10 | val loss: 2.708 | val uuas: 0.156\n",
      "epoch: 20 | val loss: 1.118 | val uuas: 0.329\n",
      "epoch: 30 | val loss: 0.912 | val uuas: 0.432\n",
      "epoch: 40 | val loss: 0.822 | val uuas: 0.486\n",
      "epoch: 50 | val loss: 0.773 | val uuas: 0.521\n",
      "epoch: 60 | val loss: 0.745 | val uuas: 0.541\n",
      "epoch: 70 | val loss: 0.722 | val uuas: 0.563\n",
      "epoch: 80 | val loss: 0.709 | val uuas: 0.571\n",
      "epoch: 90 | val loss: 0.703 | val uuas: 0.583\n",
      "epoch: 100 | val loss: 0.691 | val uuas: 0.586\n",
      "epoch: 110 | val loss: 0.689 | val uuas: 0.591\n",
      "epoch: 120 | val loss: 0.687 | val uuas: 0.594\n",
      "val loss did not improve for 10 epochs, stopping training\n",
      "test uuas of structural pos probe using gpt2fr embeddings: 0.471, test loss: 1.036\n",
      "correlation b/w PoS accuracy and uuas of structural probe per sentence on test set using gpt2fr embeddings: 0.124\n",
      "CPU times: user 2h 34min 12s, sys: 7min 35s, total: 2h 41min 48s\n",
      "Wall time: 10min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train structural probe\n",
    "params = TrainingParams()\n",
    "try:\n",
    "    str_probe_model = torch.load(f'{model_dir}/str_probe.pt')\n",
    "    print(f'loaded saved structural probe model using {lm_name} embeddings')\n",
    "except FileNotFoundError:\n",
    "    str_probe_model = StructuralProbe(train_data_str[0][0].shape[1], rank=64)\n",
    "    str_probe_model, _, _ = train_structural_probe(str_probe_model, train_data_str, val_data_str, params)\n",
    "    torch.save(str_probe_model, f'{model_dir}/str_probe.pt')\n",
    "\n",
    "# test\n",
    "test_loader_str = DataLoader(test_data_str, batch_size=params.batch_size, shuffle=False, collate_fn=pad_collate_fn)\n",
    "test_loss_str, test_uuas_str_avg, test_uuas_str   = evaluate_probe(str_probe_model, test_loader_str, L1DistanceLoss())\n",
    "print(f'test uuas of structural pos probe using {lm_name} embeddings: {test_uuas_str_avg:.3f}, test loss: {test_loss_str:.3f}')\n",
    "\n",
    "# compute correlation b/w PoS accuracy and uuas of structural probe on test set\n",
    "corr_pos_acc_uuas_test = spearmanr([test_accs_pos_sent[i] for i in range(len(test_accs_pos_sent)) if test_uuas_str[i] != -1], [x for x in test_uuas_str if x != -1])[0]\n",
    "print(f'correlation b/w PoS accuracy and uuas of structural probe per sentence on test set using {lm_name} embeddings: {corr_pos_acc_uuas_test:.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Control tasks for structural probe\n",
    "We design a control task for the structural probe by generating random distances and MSTs, and training the structural probe on them. If the structural probe is actually probing the structural information, it should perform relatively worse on the control task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating data for structural control probe...\n",
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1476/1476 [00:00<00:00, 1701.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1476/1476 [00:00<00:00, 1696.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 416/416 [00:00<00:00, 1731.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training structural probe with gpt2fr embeddings...\n",
      "epoch: 0 | val loss: 69.148 | val uuas: 0.108\n",
      "epoch: 10 | val loss: 7.394 | val uuas: 0.110\n",
      "epoch: 20 | val loss: 6.765 | val uuas: 0.109\n",
      "epoch: 30 | val loss: 6.589 | val uuas: 0.107\n",
      "epoch: 40 | val loss: 6.509 | val uuas: 0.107\n",
      "epoch: 50 | val loss: 6.462 | val uuas: 0.108\n",
      "epoch: 60 | val loss: 6.430 | val uuas: 0.108\n",
      "epoch: 70 | val loss: 6.408 | val uuas: 0.107\n",
      "epoch: 80 | val loss: 6.391 | val uuas: 0.107\n",
      "epoch: 90 | val loss: 6.380 | val uuas: 0.107\n",
      "epoch: 100 | val loss: 6.368 | val uuas: 0.106\n",
      "epoch: 110 | val loss: 6.361 | val uuas: 0.106\n",
      "epoch: 120 | val loss: 6.356 | val uuas: 0.107\n",
      "epoch: 130 | val loss: 6.349 | val uuas: 0.108\n",
      "epoch: 140 | val loss: 6.344 | val uuas: 0.107\n",
      "epoch: 150 | val loss: 6.341 | val uuas: 0.108\n",
      "epoch: 160 | val loss: 6.338 | val uuas: 0.108\n",
      "epoch: 170 | val loss: 6.335 | val uuas: 0.107\n",
      "val loss did not improve for 10 epochs, stopping training\n",
      "test uuas of structural control probe using gpt2fr embeddings: 0.120, test loss: 7.406\n",
      "CPU times: user 3h 42min 35s, sys: 10min 45s, total: 3h 53min 20s\n",
      "Wall time: 15min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def create_control_distances(corpus_path):\n",
    "    '''Create a list of control distances for each sentence in the corpus.'''\n",
    "    corpus = parse_corpus(corpus_path)\n",
    "    all_distances = []\n",
    "\n",
    "    for item in tqdm(corpus):\n",
    "        tokentree = item.to_tree()\n",
    "        ete_tree = tokentree_to_ete(tokentree)\n",
    "        sen_len = len(ete_tree.search_nodes())\n",
    "        # generate a sen_len x sen_len matrix of random distances between 1 and sen_len\n",
    "        distances = np.random.randint(1, sen_len + 1, size=(sen_len, sen_len))\n",
    "        # set the diagonal elements to zero \n",
    "        np.fill_diagonal(distances, 0)\n",
    "        # convert the NumPy array to a PyTorch tensor\n",
    "        distances_tensor = torch.from_numpy(distances)\n",
    "        all_distances.append(distances_tensor)\n",
    "\n",
    "    return all_distances\n",
    "\n",
    "try:\n",
    "    train_data_str_control = torch.load(f'{data_dir}/train_data_str_control.pt')\n",
    "    val_data_str_control = torch.load(f'{data_dir}/val_data_str_control.pt')\n",
    "    test_data_str_control = torch.load(f'{data_dir}/test_data_str_control.pt')\n",
    "except FileNotFoundError:\n",
    "    print('creating data for structural control probe...')\n",
    "    print('train')\n",
    "    train_control_distances = create_control_distances(train_path)\n",
    "    print('val')\n",
    "    val_control_distances = create_control_distances(val_path)\n",
    "    print('test')\n",
    "    test_control_distances = create_control_distances(test_path)\n",
    "    train_data_str_control = MyDataset(train_data_str.x, train_control_distances)\n",
    "    val_data_str_control = MyDataset(val_data_str.x, val_control_distances)\n",
    "    test_data_str_control = MyDataset(test_data_str.x, test_control_distances)\n",
    "    torch.save(train_data_str_control, f'{model_dir}/train_data_str_control.pt')\n",
    "    torch.save(val_data_str_control, f'{model_dir}/val_data_str_control.pt')\n",
    "    torch.save(test_data_str_control, f'{model_dir}/test_data_str_control.pt')\n",
    "\n",
    "# train structural control probe\n",
    "try:\n",
    "    str_probe_control_model = torch.load(f'{model_dir}/str_probe_control.pt')\n",
    "    print(f'loaded saved structural control probe model using {lm_name} embeddings')\n",
    "except FileNotFoundError:\n",
    "    str_probe_control_model = StructuralProbe(train_data_str_control[0][0].shape[1], rank=64)\n",
    "    str_probe_control_model, _, _ = train_structural_probe(str_probe_control_model, train_data_str_control, val_data_str_control, params)\n",
    "    torch.save(str_probe_control_model, f'{model_dir}/str_probe_control.pt')\n",
    "\n",
    "# test\n",
    "test_loader_str_control = DataLoader(test_data_str_control, batch_size=params.batch_size, shuffle=False, collate_fn=pad_collate_fn)\n",
    "test_loss_str_control, test_uuas_str_control_avg, test_uuas_str_control = evaluate_probe(str_probe_control_model, test_loader_str_control, L1DistanceLoss())\n",
    "print(f'test uuas of structural control probe using {lm_name} embeddings: {test_uuas_str_control_avg:.3f}, test loss: {test_loss_str_control:.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print trees to LaTeX\n",
    "Code to print dependency tree plots in LaTeX like those of Figure 2 in the Structural Probing paper. \n",
    "**N.B.**: for the latex tikz tree the first token in a sentence has index 1 (instead of 0), so take that into account with the predicted and gold edges that you pass to the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tikz(predicted_edges, gold_edges, words):\n",
    "    \"\"\" Turns edge sets on word (nodes) into tikz dependency LaTeX.\n",
    "    Parameters\n",
    "    ----------\n",
    "    predicted_edges : Set[Tuple[int, int]]\n",
    "        Set (or list) of edge tuples, as predicted by your probe.\n",
    "    gold_edges : Set[Tuple[int, int]]\n",
    "        Set (or list) of gold edge tuples, as obtained from the treebank.\n",
    "    words : List[str]\n",
    "        List of strings representing the tokens in the sentence.\n",
    "    \"\"\"\n",
    "\n",
    "    string = \"\"\"\\\\begin{dependency}[hide label, edge unit distance=.5ex]\n",
    "    \\\\begin{deptext}[column sep=0.05cm]\n",
    "    \"\"\"\n",
    "\n",
    "    string += (\n",
    "        \"\\\\& \".join([x.replace(\"$\", \"\\$\").replace(\"&\", \"+\") for x in words])\n",
    "        + \" \\\\\\\\\\n\"\n",
    "    )\n",
    "    string += \"\\\\end{deptext}\" + \"\\n\"\n",
    "    for i_index, j_index in gold_edges:\n",
    "        string += \"\\\\depedge[-]{{{}}}{{{}}}{{{}}}\\n\".format(i_index, j_index, \".\")\n",
    "    for i_index, j_index in predicted_edges:\n",
    "        string += f\"\\\\depedge[-,edge style={{red!60!}}, edge below]{{{i_index}}}{{{j_index}}}{{.}}\\n\"\n",
    "    string += \"\\\\end{dependency}\\n\"\n",
    "    print(string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

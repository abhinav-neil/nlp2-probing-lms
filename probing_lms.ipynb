{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probing Language Models for Structure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports <a id=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os, random\n",
    "import gdown\n",
    "from collections import defaultdict\n",
    "from lstm.model import RNNModel\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from conllu import parse_incr, TokenList\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, RobertaTokenizer, RobertaModel, OPTModel, AutoTokenizer\n",
    "from ete3 import Tree\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Language models <a id=\"models\"></a>\n",
    "\n",
    "### Transformer\n",
    "We will use the `transformers` library of Huggingface: https://github.com/huggingface/transformers\n",
    "\n",
    "### LSTM\n",
    "We will use the Gulordava LSTM from the Colorless Green RNNs paper: https://arxiv.org/pdf/1803.11138.pdf. The weigths are available at https://drive.google.com/file/d/19Lp3AM4NEPycp_IBgoHfLc_V456pmUom/view?usp=sharing. The original code is available at https://github.com/facebookresearch/colorlessgreenRNNs/blob/master/src/language_models/model.py. The code has been altered to only output the hidden states that we are interested in. For further experiments, have a look at the original code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at facebook/opt-125m were not used when initializing OPTModel: ['lm_head.weight']\n",
      "- This IS expected if you are initializing OPTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing OPTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# load models and tokenizers\n",
    "# LSTM\n",
    "lstm_path = 'lstm/state_dict.pt'  # path to saved lstm model\n",
    "if not os.path.exists(lstm_path):\n",
    "    lstm_model_url = 'https://drive.google.com/u/0/uc?id=19Lp3AM4NEPycp_IBgoHfLc_V456pmUom'\n",
    "    gdown.download(lstm_model_url, lstm_path, quiet=False)\n",
    "lstm_model = RNNModel('LSTM', 50001, 650, 650, 2)\n",
    "lstm_model.load_state_dict(torch.load(lstm_path))\n",
    "# the LSTM uses a vocab dict that maps a token to an id, instead of a tokenizer\n",
    "with open('lstm/vocab.txt') as f:\n",
    "    w2i = {w.strip(): i for i, w in enumerate(f)}\n",
    "vocab = defaultdict(lambda: w2i[\"<unk>\"])\n",
    "vocab.update(w2i)\n",
    "\n",
    "# distilgpt2\n",
    "gpt2d_model = GPT2LMHeadModel.from_pretrained('distilgpt2')\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
    "\n",
    "# gpt2-medium\n",
    "gpt2m_model = GPT2LMHeadModel.from_pretrained('gpt2-medium')\n",
    "gpt2m_tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
    "\n",
    "# french gpt2\n",
    "gpt2fr_model = GPT2LMHeadModel.from_pretrained(\"antoiloui/belgpt2\")\n",
    "gpt2fr_tokenizer = GPT2Tokenizer.from_pretrained(\"antoiloui/belgpt2\")\n",
    "\n",
    "# italian gpt2\n",
    "gpt2it_model = GPT2LMHeadModel.from_pretrained('LorenzoDeMattei/GePpeTto')\n",
    "gpt2it_tokenizer = GPT2Tokenizer.from_pretrained('LorenzoDeMattei/GePpeTto')\n",
    "\n",
    "# roberta\n",
    "roberta_model = RobertaModel.from_pretrained('roberta-base')\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# opt\n",
    "opt_model = OPTModel.from_pretrained('facebook/opt-125m')\n",
    "opt_tokenizer = AutoTokenizer.from_pretrained('facebook/opt-125m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "globals"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LM: lstm | using sample: False | data dir: data/lstm | model dir: models/lstm/\n",
      "model sizes (# params):\n",
      "lstm: 71.82M\n",
      "gpt2d: 81.91M\n",
      "roberta: 124.65M\n",
      "gpt2m: 354.82M\n",
      "gpt2fr: 124.44M\n",
      "gpt2it: 108.88M\n",
      "opt: 125.24M\n"
     ]
    }
   ],
   "source": [
    "# set global variables\n",
    "lm = lstm_model  # language model\n",
    "language = 'en' # language, one of 'en', 'fr', 'it'\n",
    "use_sample = False   # use a small sample of the data for faster debugging\n",
    "run_mode = 'default'  # run mode; 'default' uses contextual reps of LM, 'baseline-nc' uses non-contextualized word embeddings\n",
    "lm_names = {lstm_model: 'lstm', gpt2d_model: 'gpt2d', roberta_model: 'roberta', gpt2m_model: 'gpt2m', gpt2fr_model: 'gpt2fr', gpt2it_model: 'gpt2it', opt_model: 'opt'}\n",
    "lm_name = lm_names[lm]\n",
    "tokenizers = {'lstm': vocab, 'gpt2d': gpt_tokenizer, 'roberta': roberta_tokenizer, 'gpt2m': gpt2m_tokenizer, 'gpt2fr': gpt2fr_tokenizer, 'gpt2it': gpt2it_tokenizer, 'opt': opt_tokenizer}\n",
    "tokenizer = tokenizers[lm_name]\n",
    "data_dir = f'data/sample/{lm_name}' if use_sample else f'data/{lm_name}'  # path to data\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "model_dir = f'models/sample/{lm_name}/' if use_sample else f'models/{lm_name}/'  # path to models\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "print(f'LM: {lm_name} | using sample: {use_sample} | data dir: {data_dir} | model dir: {model_dir}')\n",
    "\n",
    "# print model sizes\n",
    "print('model sizes (# params):')\n",
    "for model in [lstm_model, gpt2d_model, roberta_model, gpt2m_model, gpt2fr_model, gpt2it_model, opt_model]:\n",
    "    print(f'{lm_names[model]}: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PoS probing <a id=\"pos probe\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Generate data for PoS probe <a id=\"pos data\"></a>\n",
    "We will use a treebank corpus for our data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 16.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "def parse_corpus(filename: str) -> List[TokenList]:\n",
    "    data_file = open(filename, encoding=\"utf-8\")\n",
    "    ud_parses = list(parse_incr(data_file))\n",
    "    \n",
    "    return ud_parses\n",
    "\n",
    "# ud_parses_sample = parse_corpus('data/sample/en_ewt-ud-train.conllu')\n",
    "\n",
    "# fetch sentence representations\n",
    "def fetch_sen_reps(ud_parses: List[TokenList], model=lm, tokenizer=tokenizer, concat=True, run_mode='default') -> torch.Tensor:\n",
    "    '''\n",
    "    returns sentence representations (embeddings) for a list of sentences, by first tokenizing them and then passing them through the model\n",
    "    inputs:\n",
    "        ud_parses: list of sentences, each sentence is a list of tokens, each token is a dictionary (conllu format)\n",
    "        model: the language model (encoder) to use for sentence representation, either an LSTM or a transformer-based model\n",
    "        tokenizer: tokenizer to use for the language model\n",
    "        run_mode: either 'default' or 'baseline-nc'; 'default' uses contextualized representations of the LM, 'baseline-nc' uses non-contextualized word embeddings\n",
    "    returns:\n",
    "        sent_reps: a tensor of shape (num_tokens_in_corpus, representation_size), containing the sentence representations (embeddings) for all sentences in the corpus\n",
    "    '''\n",
    "    model.eval()    # set model to evaluation mode\n",
    "    sent_reps = []\n",
    "    for sent in tqdm(ud_parses):\n",
    "        # LSTM\n",
    "        if model == lstm_model:\n",
    "            # tokenize\n",
    "            sent_tokenized = torch.tensor([tokenizer[token['form']] for token in sent if token[\"upostag\"] != \"_\"])\n",
    "            # get sentence representation\n",
    "            with torch.no_grad():\n",
    "                out_rep = model(sent_tokenized.unsqueeze(0), model.init_hidden(1)).squeeze(0)\n",
    "                \n",
    "        # transformers\n",
    "        elif model in [gpt2d_model, gpt2m_model, gpt2fr_model, gpt2it_model, roberta_model, opt_model]:\n",
    "            token_ids, att_masks = [], []\n",
    "            add_space = False   # whether to add a space before the token\n",
    "            for token in sent:\n",
    "                if token[\"upostag\"] == \"_\": # skip invalid/multiword tokens\n",
    "                    continue\n",
    "                # tokenize\n",
    "                if model == roberta_model:\n",
    "                    tokenized = tokenizer.encode_plus(\" \" + token['form'] if add_space else token['form'], return_tensors='pt')\n",
    "                else:\n",
    "                    tokenized = tokenizer(\" \" + token['form'], return_tensors='pt') if add_space else tokenizer(token['form'], return_tensors='pt')\n",
    "\n",
    "                token_ids.append(tokenized['input_ids'][0])\n",
    "                att_masks.append(tokenized['attention_mask'][0])\n",
    "                # check whether to add a space before the next token\n",
    "                add_space = False if token['misc'] is not None and token['misc'].get('SpaceAfter', '') == 'No' else True\n",
    "                \n",
    "            # get sentence representation\n",
    "            with torch.no_grad():\n",
    "                # return input embeddings if run_mode is 'baseline-nc'\n",
    "                if run_mode == 'baseline-nc':\n",
    "                    out = model.get_input_embeddings()(torch.hstack(token_ids))\n",
    "                # return encoded representations\n",
    "                elif model == roberta_model or model == opt_model:\n",
    "                    out = model(input_ids=torch.hstack(token_ids).unsqueeze(0), attention_mask=torch.hstack(att_masks).unsqueeze(0), output_hidden_states=True).last_hidden_state.squeeze(0)\n",
    "                else:\n",
    "                    out = model(input_ids=torch.hstack(token_ids), attention_mask=torch.hstack(att_masks), output_hidden_states=True).hidden_states[-1]\n",
    "\n",
    "            # average over parts belonging to the same token\n",
    "            out_rep = torch.zeros(len(token_ids), out.shape[-1])\n",
    "            num_sub_tokens = 0\n",
    "            for i in range(out_rep.shape[0]):\n",
    "                out_rep[i] = out[i + num_sub_tokens: i + num_sub_tokens + len(token_ids[i])].mean(0)\n",
    "                num_sub_tokens += len(token_ids[i]) - 1\n",
    "                \n",
    "        else :\n",
    "            raise ValueError('model should be one of: lstm_model, gpt2d_model, gpt2m_model, gpt2fr_model, roberta_model')       \n",
    "        sent_reps += out_rep if concat else [out_rep]\n",
    "    \n",
    "    # stack token representations of entire corpus\n",
    "    if concat:\n",
    "        sent_reps = torch.vstack(sent_reps)\n",
    "    \n",
    "    return sent_reps\n",
    "\n",
    "# test fetch_sen_reps\n",
    "def error_msg(model_name, gold_embs, embs, i2w):\n",
    "    with open(f'{model_name}_tokens1.pickle', 'rb') as f:\n",
    "        sen_tokens = pickle.load(f)\n",
    "        \n",
    "    diff = torch.abs(embs - gold_embs)\n",
    "    max_diff = torch.max(diff)\n",
    "    avg_diff = torch.mean(diff)\n",
    "    \n",
    "    print(f\"{model_name} embeddings don't match!\")\n",
    "    print(f\"Max diff.: {max_diff:.4f}\\nMean diff. {avg_diff:.4f}\")\n",
    "\n",
    "    print(\"\\nCheck if your tokenization matches with the original tokenization:\")\n",
    "    for idx in sen_tokens.squeeze():\n",
    "        if isinstance(i2w, list):\n",
    "            token = i2w[idx]\n",
    "        else:\n",
    "            token = i2w.convert_ids_to_tokens(idx.item())\n",
    "        print(f\"{idx:<6} {token}\")\n",
    "\n",
    "\n",
    "def assert_sen_reps(model, tokenizer, lstm, vocab):\n",
    "    with open('distilgpt2_emb1.pickle', 'rb') as f:\n",
    "        distilgpt2_emb1 = pickle.load(f)\n",
    "        \n",
    "    with open('lstm_emb1.pickle', 'rb') as f:\n",
    "        lstm_emb1 = pickle.load(f)\n",
    "    \n",
    "    corpus = parse_corpus('data/sample/en_ewt-ud-train.conllu')[:1]\n",
    "    \n",
    "    own_distilgpt2_emb1 = fetch_sen_reps(corpus, model, tokenizer)\n",
    "    own_lstm_emb1 = fetch_sen_reps(corpus, lstm, vocab)\n",
    "    \n",
    "    assert distilgpt2_emb1.shape == own_distilgpt2_emb1.shape, \\\n",
    "        f\"Distilgpt2 shape mismatch: {distilgpt2_emb1.shape} (gold) vs. {own_distilgpt2_emb1.shape} (yours)\"\n",
    "    assert lstm_emb1.shape == own_lstm_emb1.shape, \\\n",
    "        f\"LSTM shape mismatch: {lstm_emb1.shape} (gold) vs. {own_lstm_emb1.shape} (yours)\"\n",
    "\n",
    "    if not torch.allclose(distilgpt2_emb1, own_distilgpt2_emb1, rtol=1e-3, atol=1e-3):\n",
    "        error_msg(\"distilgpt2\", distilgpt2_emb1, own_distilgpt2_emb1, tokenizer)\n",
    "    if not torch.allclose(lstm_emb1, own_lstm_emb1, rtol=1e-3, atol=1e-3):\n",
    "        error_msg(\"lstm\", lstm_emb1, own_lstm_emb1, list(vocab.keys()))\n",
    "\n",
    "\n",
    "assert_sen_reps(gpt2d_model, gpt_tokenizer, lstm_model, vocab)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting PoS labels\n",
    "Next, we should define a function that extracts the corresponding POS labels for each activation. These labels will be transformed to a tensor containing the label index for each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch POS tags\n",
    "def fetch_pos_tags(ud_parses: List[TokenList], pos_vocab: Optional[Dict[str, int]] = None) -> Tuple[torch.Tensor, Dict[str, int]]:\n",
    "\t'''\n",
    "\treturn the POS tags for all tokens in the corpus\n",
    "\tinputs:\n",
    "\t\tud_parses: list of sentences, each sentence is a list of tokens, each token is a dictionary (conllu format)\n",
    "\t\tpos_vocab: a dictionary mapping POS tags to integers (optional)\n",
    "\treturns:\n",
    "\t\tpos_tags: a tensor of shape (num_tokens_in_corpus,) containing the POS tags for all tokens in the corpus\n",
    "\t'''\n",
    "\tif pos_vocab is None:\n",
    "\t\tpos_vocab = defaultdict(int)\n",
    "\t\tfor sent in ud_parses:\n",
    "\t\t\tfor token in sent:\n",
    "\t\t\t\t# add new POS tags to vocab\n",
    "\t\t\t\tif token[\"upostag\"] not in pos_vocab and token[\"upostag\"] != \"_\":\n",
    "\t\t\t\t\tpos_vocab[token[\"upostag\"]] = len(pos_vocab)\n",
    "\n",
    "\tpos_tags = [torch.tensor(pos_vocab[token[\"upostag\"]])\n",
    "\t\t\t\t\t\t\t for sent in ud_parses for token in sent if token[\"upostag\"] != \"_\"]\n",
    "\tpos_tags = torch.vstack(pos_tags).squeeze()\n",
    "\n",
    "\treturn pos_tags, pos_vocab\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge representations & PoS tags\n",
    "We merge sentence representations (features) and PoS tags (labels) to create dataloaders for the probe. We pass the `train_vocab` to the data creation of the `dev` and `test` data is that we want to use the same label vocabulary across the different train/val/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train data: 204585 | size of val data: 25148 | size of test data: 25096\n",
      "the test set has an avg sentence length of 12.08 with 1303 short sentences and 774 long sentences\n",
      "\n",
      "CPU times: user 373 ms, sys: 96.5 ms, total: 469 ms\n",
      "Wall time: 467 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create 2 tensors for a .conllu file: 1 containing the token representations, and 1 containing the (tokenized) pos_tags\n",
    "def create_data(filename, lm, tokenizer, run_mode, pos_vocab=None):\n",
    "    # print('parsing corpus...')\n",
    "    ud_parses = parse_corpus(filename)\n",
    "    # print(f'fetching sentence representations using {lm_name}...')\n",
    "    sen_reps = fetch_sen_reps(ud_parses=ud_parses, model=lm, tokenizer=tokenizer, run_mode=run_mode)\n",
    "    # print('fetching POS tags...')\n",
    "    pos_tags, pos_vocab = fetch_pos_tags(ud_parses, pos_vocab=pos_vocab)    \n",
    "    return sen_reps, pos_tags, pos_vocab\n",
    "\n",
    "# create datasets and dataloaders\n",
    "# define a custom PyTorch dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "# create train/val/test data\n",
    "# path to the .conllu files\n",
    "if language == 'en':\n",
    "    train_path = 'data/sample/en_ewt-ud-train.conllu' if use_sample else 'data/en_ewt-ud-train.conllu'\n",
    "    val_path = 'data/sample/en_ewt-ud-val.conllu' if use_sample else 'data/en_ewt-ud-dev.conllu'\n",
    "    test_path = 'data/sample/en_ewt-ud-test.conllu' if use_sample else 'data/en_ewt-ud-test.conllu'\n",
    "elif language == 'fr':\n",
    "    train_path = 'data/fr_gsd-ud-dev.conllu'\n",
    "    val_path = 'data/fr_gsd-ud-dev.conllu'\n",
    "    test_path = 'data/fr_gsd-ud-test.conllu'\n",
    "elif language == 'it':\n",
    "    train_path = 'data/it_isdt-ud-train.conllu'\n",
    "    val_path = 'data/it_isdt-ud-dev.conllu'\n",
    "    test_path = 'data/it_isdt-ud-test.conllu'\n",
    "else:\n",
    "    raise ValueError(f'language {language} not supported')\n",
    "\n",
    "suffix = '' if run_mode == 'default' else '_nc' if run_mode == 'baseline-nc' else None\n",
    "train_data_path = f'{data_dir}/train_data_pos{suffix}.pt'\n",
    "train_vocab_pos_path = f'{data_dir}/train_vocab_pos.pt'\n",
    "val_data_path = f'{data_dir}/val_data_pos{suffix}.pt'\n",
    "test_data_path = f'{data_dir}/test_data_pos{suffix}.pt'\n",
    "try:\n",
    "    train_data_pos = torch.load(train_data_path)\n",
    "    train_vocab_pos = torch.load(train_vocab_pos_path)\n",
    "    val_data_pos = torch.load(val_data_path)\n",
    "    test_data_pos = torch.load(test_data_path)\n",
    "except FileNotFoundError:\n",
    "    print(f'creating train/val/test data using {lm_name} embeddings with {run_mode} run mode...')\n",
    "    train_x_pos, train_y_pos, train_vocab_pos = create_data(train_path, lm=lm, tokenizer=tokenizer, run_mode=run_mode)\n",
    "    val_x_pos, val_y_pos, _ = create_data(val_path, lm=lm, tokenizer=tokenizer, run_mode=run_mode, pos_vocab=train_vocab_pos)\n",
    "    test_x_pos, test_y_pos, _ = create_data(test_path, lm=lm, tokenizer=tokenizer, run_mode=run_mode, pos_vocab=train_vocab_pos)\n",
    "    train_data_pos = MyDataset(train_x_pos, train_y_pos)\n",
    "    val_data_pos = MyDataset(val_x_pos, val_y_pos)\n",
    "    test_data_pos = MyDataset(test_x_pos, test_y_pos)\n",
    "    torch.save(train_vocab_pos, train_vocab_pos_path)\n",
    "    torch.save(train_data_pos, train_data_path)\n",
    "    torch.save(val_data_pos, val_data_path)\n",
    "    torch.save(test_data_pos, test_data_path)\n",
    "    \n",
    "print(f'size of train data: {len(train_data_pos)} | size of val data: {len(val_data_pos)} | size of test data: {len(test_data_pos)}')\n",
    "\n",
    "# find long & short sentences in test set\n",
    "test_corpus = parse_corpus(test_path)\n",
    "avg_sen_len_test = sum([len(sen) for sen in test_corpus]) / len(test_corpus)\n",
    "idxs_short_sent_test = [i for i, sen in enumerate(test_corpus) if len(sen) <= avg_sen_len_test]\n",
    "idxs_long_sent_test = [i for i, sen in enumerate(test_corpus) if len(sen) > avg_sen_len_test]\n",
    "print(f'the test set has an avg sentence length of {avg_sen_len_test:.2f} with {len(idxs_short_sent_test)} short sentences and {len(idxs_long_sent_test)} long sentences\\n')\n",
    "# print(f'examples of short sentences: {test_corpus[idxs_short_sent_test[0]].metadata[\"text\"]}\\n {test_corpus[idxs_short_sent_test[1]].metadata[\"text\"]}')\n",
    "# print(f'examples of long sentences: {test_corpus[idxs_long_sent_test[0]].metadata[\"text\"]}\\n {test_corpus[idxs_long_sent_test[1]].metadata[\"text\"]}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train & test PoS probe <a name=\"dc\"></a>\n",
    "We will train a PoS probe using simple linear model. Refer \"Designing and Interpreting Probes with Control Tasks\" by Hewitt and Liang (esp. Sec. 3.2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic classifier/probe\n",
    "# class to store training parameters\n",
    "class TrainingParams:\n",
    "    def __init__(self, lr=1e-3, batch_size=256, num_epochs=1000, patience=10):\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.patience = patience\n",
    "        \n",
    "def set_seed(seed):\n",
    "    # Set seed for random, numpy, PyTorch\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "        \n",
    "def train_pos_probe(model, train_data, val_data, params, seed=42, print_every=10):\n",
    "    set_seed(seed)  # set seed for reproducibility\n",
    "    # create dataloaders\n",
    "    train_loader = DataLoader(train_data, batch_size=params.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=params.batch_size, shuffle=False)\n",
    "    # define loss and optimizer\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=params.lr)\n",
    "    val_losses, val_accs = [], []\n",
    "\n",
    "    # training/val loop\n",
    "    for epoch in range(params.num_epochs):\n",
    "        # train\n",
    "        model.train()\n",
    "        for train_x, train_y in train_loader:\n",
    "            out = model(train_x)\n",
    "            loss = criterion(out, train_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            \n",
    "        # validate\n",
    "        model.eval()\n",
    "        val_losses_epoch, val_accs_epoch = [], []\n",
    "        for val_x, val_y in val_loader:\n",
    "            with torch.no_grad():\n",
    "                out = model(val_x)\n",
    "                loss = criterion(out, val_y)\n",
    "                val_losses_epoch.append(loss.item())\n",
    "                preds_val = torch.argmax(out, dim=1)\n",
    "                acc = (preds_val == val_y).sum().item() / len(val_y)\n",
    "                val_accs_epoch.append(acc)\n",
    "                \n",
    "        val_loss_epoch = np.mean(val_losses_epoch)\n",
    "        val_acc_epoch = np.mean(val_accs_epoch)\n",
    "        val_losses.append(val_loss_epoch)\n",
    "        val_accs.append(val_acc_epoch)\n",
    "        \n",
    "        if epoch % print_every == 0:\n",
    "            print(f'epoch: {epoch} | val loss: {val_loss_epoch:.3f} | val acc: {val_acc_epoch:.3f}')\n",
    "        \n",
    "        # early stopping\n",
    "        if epoch >= params.patience and val_loss_epoch >= val_losses[-params.patience]:\n",
    "            print(f'val loss did not improve for {params.patience} epochs, stopping training')\n",
    "            break\n",
    "        \n",
    "    # save model\n",
    "    # model_path = f'{model_dir}/linear_pos_probe.pt'\n",
    "    # torch.save(model, model_path)\n",
    "        \n",
    "    return model, val_losses, val_accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy of linear pos probe using gpt2d embeddings and default run mode is 0.024 overall, (0.012 for short sentences, 0.009 for long sentences)\n"
     ]
    }
   ],
   "source": [
    "# train pos probe\n",
    "pos_probe_type = 'linear' # type of PoS probe, either 'linear' or 'nonlinear'\n",
    "pos_model_path = f'{model_dir}/{pos_probe_type}_pos_probe{suffix}.pt'\n",
    "try:\n",
    "    pos_probe_model = torch.load(pos_model_path)\n",
    "except FileNotFoundError:\n",
    "    params = TrainingParams()\n",
    "    if pos_probe_type == 'linear':\n",
    "        # single linear layer with input_dim = embedding_dim and output_dim = len(pos_vocab), no activation\n",
    "        pos_probe_model = nn.Linear(train_data_pos.x.shape[1], len(train_vocab_pos))\n",
    "    elif pos_probe_type == 'nonlinear':\n",
    "        # two linear layers of shape (embedding_dim, hidden_dim) and (hidden_dim, len(pos_vocab)), with ReLU activation in between\n",
    "        hidden_dim = 100\n",
    "        pos_probe_model = nn.Sequential(\n",
    "            nn.Linear(train_data_pos.x.shape[1], hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, len(train_vocab_pos)))\n",
    "    else:\n",
    "        raise ValueError('pos_probe_type must be linear or nonlinear')\n",
    "    \n",
    "    print(f'training {pos_probe_type} pos probe with {lm_name} embeddings with {run_mode} run mode...')\n",
    "    pos_probe_model, _, _ = train_pos_probe(pos_probe_model, train_data_pos, val_data_pos, params)\n",
    "    torch.save(pos_probe_model, pos_model_path)\n",
    "\n",
    "# test\n",
    "out_test = pos_probe_model(test_data_pos.x)\n",
    "preds_test_pos = torch.argmax(out_test, dim=1)\n",
    "test_acc_pos = (preds_test_pos == test_data_pos.y).sum().item() / len(test_data_pos.y)\n",
    "test_acc_pos_short = (preds_test_pos[idxs_short_sent_test] == test_data_pos.y[idxs_short_sent_test]).sum().item() / len(test_data_pos.y[idxs_short_sent_test])\n",
    "test_acc_pos_long = (preds_test_pos[idxs_long_sent_test] == test_data_pos.y[idxs_long_sent_test]).sum().item() / len(test_data_pos.y[idxs_long_sent_test])\n",
    "print(f'test accuracy of {pos_probe_type} pos probe using {lm_name} embeddings and {run_mode} run mode is {test_acc_pos:.3f} overall, ({test_acc_pos_short:.3f} for short sentences, {test_acc_pos_long:.3f} for long sentences)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg PoS accuracy of 1st 5 sentences in test set using gpt2m embeddings and baseline-nc run mode: [0.8571428571428571, 0.9130434782608695, 0.8888888888888888, 0.92, 0.8387096774193549]\n"
     ]
    }
   ],
   "source": [
    "# compute avg PoS accuracy per sentence in test set\n",
    "def get_pos_acc_sent(preds_pos, y_pos):\n",
    "    '''\n",
    "    Compute average PoS accuracy per sentence in test set\n",
    "    Inputs:\n",
    "        ud_parses: list of lists of UD parse trees\n",
    "        preds_pos: predicted PoS tags\n",
    "        y_pos: true PoS tags\n",
    "    Returns:\n",
    "        accs_pos_sent: list of average PoS accuracies per sentence\n",
    "    '''\n",
    "    token_count = 0\n",
    "    accs_pos_sent = []\n",
    "    for sent in test_ud_parses:\n",
    "        acc_pos_sent = (preds_pos[token_count:token_count+len(sent)] == y_pos[token_count:token_count+len(sent)]).sum().item() / len(sent)\n",
    "        accs_pos_sent.append(acc_pos_sent)\n",
    "        token_count += len(sent)\n",
    "    return accs_pos_sent\n",
    "\n",
    "test_ud_parses = parse_corpus(test_path)\n",
    "test_accs_pos_sent = get_pos_acc_sent(preds_test_pos, test_y_pos)\n",
    "print(f'avg PoS accuracy of 1st 5 sentences in test set using {lm_name} embeddings and {run_mode} run mode: {test_accs_pos_sent[:5]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Control tasks for PoS probe <a name=\"control-tasks-pos\"></a>\n",
    "We will train a control task to check if the probe is actually probing the linguistic information. We will use the same model as the probe, but we will train it to predict a random label for each input. If the probe is actually probing the linguistic information, it should perform better than the control task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12543/12543 [00:00<00:00, 68637.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training control probe with opt embeddings...\n",
      "epoch: 0 | val loss: 1.347 | val acc: 0.632\n",
      "epoch: 10 | val loss: 1.175 | val acc: 0.705\n",
      "val loss did not improve for 10 epochs, stopping training\n",
      "test accuracy of control probe using opt embeddings is 0.702\n"
     ]
    }
   ],
   "source": [
    "def fetch_pos_control_labels(corpus_path: str, control_vocab=None,  len_pos_vocab: int=None) -> torch.Tensor:\n",
    "\t'''\n",
    "\tGenerate control task labels for each token in the corpus.\n",
    "\tInputs:\n",
    "\t\tud_parses: list of sentences, each sentence is a list of tokens, each token is a dictionary (conllu format)\n",
    "\t\tlen_pos_vocab: length of the pos_vocab dictionary\n",
    "\t\tcontrol_vocab: a dictionary mapping tokens to control labels (optional)\n",
    "\tReturns:\n",
    "\t\tcontrol_labels: a tensor of shape (num_tokens_in_corpus,) containing the control task labels for all tokens in the corpus\n",
    "\t\tcontrol_vocab: a dictionary mapping tokens to control labels\n",
    "\t'''\n",
    "\tud_parses = parse_corpus(corpus_path)\n",
    "\tif not control_vocab:\n",
    "\t\tcontrol_vocab = defaultdict(int)\n",
    "\t\tfor sent in tqdm(ud_parses):\n",
    "\t\t\tfor token in sent:\n",
    "\t\t\t\tif token[\"upostag\"] == \"_\":\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tif token['form'] not in control_vocab:\n",
    "\t\t\t\t\tcontrol_vocab[token['form']] = np.random.randint(len_pos_vocab)\n",
    "\n",
    "\tcontrol_labels = [torch.tensor(control_vocab[token['form']]) for sent in ud_parses for token in sent if token[\"upostag\"] != \"_\"]\n",
    "\tcontrol_labels = torch.vstack(control_labels).squeeze()\n",
    "\t\n",
    "\treturn control_labels, control_vocab\n",
    "# create data for control task\n",
    "train_y_pos_control, train_vocab_pos_control = fetch_pos_control_labels(train_path, None, len(train_vocab_pos))\n",
    "val_y_pos_control, _ = fetch_pos_control_labels(val_path, train_vocab_pos_control)\n",
    "test_y_pos_control, _ = fetch_pos_control_labels(test_path, train_vocab_pos_control)\n",
    "train_data_pos_control = MyDataset(train_data_pos.x, train_y_pos_control)\n",
    "val_data_pos_control = MyDataset(val_data_pos.x, val_y_pos_control)\n",
    "test_data_pos_control = MyDataset(test_data_pos.x, test_y_pos_control)\n",
    "\n",
    "# train control probe\n",
    "try:\n",
    "\tpos_control_probe_model = torch.load(f'{model_dir}/pos_control_probe.pt')\n",
    "except FileNotFoundError:\n",
    "\tparams = TrainingParams()\n",
    "\t# single linear layer with input_dim = embedding_dim and output_dim = len(pos_vocab), no activation\n",
    "\tpos_control_probe_model = nn.Linear(train_data_pos.x.shape[1], len(train_vocab_pos_control))\n",
    "\tprint(f'training control probe with {lm_name} embeddings...')\n",
    "\tpos_control_probe_model, _, _ = train_pos_probe(pos_control_probe_model, train_data_pos_control, val_data_pos_control, params)\n",
    "\ttorch.save(pos_control_probe_model, f'{model_dir}/pos_control_probe.pt')\n",
    "\n",
    "# test\n",
    "out_test = pos_control_probe_model(test_data_pos.x)\n",
    "preds_test_pos_control = torch.argmax(out_test, dim=1)\n",
    "test_acc_pos_control = (preds_test_pos_control == test_y_pos_control).sum().item() / len(test_y_pos_control)\n",
    "print(f'test accuracy of control probe using {lm_name} embeddings is {test_acc_pos_control:.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Structural probing <a name=\"structural probe\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Trees <a name=\"trees\"></a>\n",
    "\n",
    "For our gold labels, we need to recover the node distances from our parse tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to tranform trees\n",
    "def rec_tokentree_to_nltk(tokentree):\n",
    "    token = tokentree.token[\"form\"]\n",
    "    tree_str = f\"({token} {' '.join(rec_tokentree_to_nltk(t) for t in tokentree.children)})\"\n",
    "    return tree_str\n",
    "\n",
    "def tokentree_to_nltk(tokentree):\n",
    "    from nltk import Tree as NLTKTree\n",
    "    tree_str = rec_tokentree_to_nltk(tokentree)\n",
    "    return NLTKTree.fromstring(tree_str)\n",
    "\n",
    "class FancyTree(Tree):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, format=1, **kwargs)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.get_ascii(show_internal=True)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "# transform your conllu tree to an ete3.Tree, for better visualisation\n",
    "def rec_tokentree_to_ete(tokentree):\n",
    "    idx = str(tokentree.token[\"id\"])\n",
    "    children = tokentree.children\n",
    "    if children:\n",
    "        return f\"({','.join(rec_tokentree_to_ete(t) for t in children)}){idx}\"\n",
    "    else:\n",
    "        return idx\n",
    "    \n",
    "def tokentree_to_ete(tokentree):\n",
    "    newick_str = rec_tokentree_to_ete(tokentree)\n",
    "    return FancyTree(f\"{newick_str};\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing gold distances, MST & UUAS scores\n",
    "\n",
    "We label a token by its token id (converted to a string). Based on these id's we are going to retrieve the node distances. Uing the gold distances, we can compute the **minimum spanning tree (MST)**. We can then compute the Undirected Unlabeled Attachment Score (UUAS), which is expressed as:\n",
    "\n",
    "$$\\frac{\\text{number of predicted edges that are an edge in the gold parse tree}}{\\text{number of edges in the gold parse tree}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gold_distances(corpus):\n",
    "    '''Create a list of gold distances for each sentence in the corpus.'''\n",
    "    all_distances = []\n",
    "\n",
    "    for item in tqdm(corpus):\n",
    "        tokentree = item.to_tree()\n",
    "        ete_tree = tokentree_to_ete(tokentree)\n",
    "\n",
    "        sen_len = len(ete_tree.search_nodes())\n",
    "        distances = torch.zeros((sen_len, sen_len))\n",
    "\n",
    "        for node1 in ete_tree.search_nodes():\n",
    "            for node2 in ete_tree.search_nodes():\n",
    "                distances[int(node1.name)-1][int(node2.name)-1] = node1.get_distance(node2)\n",
    "\n",
    "        all_distances.append(distances)\n",
    "\n",
    "    return all_distances\n",
    "\n",
    "def create_mst(distances):\n",
    "    '''Create a minimum spanning tree from a distance matrix.'''\n",
    "    distances = torch.triu(distances).detach().numpy()\n",
    "    mst = minimum_spanning_tree(distances).toarray()\n",
    "    mst[mst>0] = 1.\n",
    "    \n",
    "    return mst\n",
    "\n",
    "# viz ete tree, gold distances, mst\n",
    "# item = corpus[5]\n",
    "# tokentree = item.to_tree()\n",
    "# ete3_tree = tokentree_to_ete(tokentree)\n",
    "# print(ete3_tree, '\\n')\n",
    "\n",
    "# gold_distance = create_gold_distances(corpus[5:6])[0]\n",
    "# print(gold_distance, '\\n')\n",
    "\n",
    "# mst = create_mst(gold_distance)\n",
    "# print(mst)\n",
    "\n",
    "def get_edges(mst):\n",
    "    '''Retrieve the edges of a minimum spanning tree.\n",
    "    Inputs: mst: np.array of shape (n, n)\n",
    "                 a minimum spanning tree of a sentence\n",
    "    Outputs: edges: set of tuples\n",
    "                the edges of the minimum spanning tree\n",
    "            '''\n",
    "    edges = np.nonzero(mst)\n",
    "    edges = list(zip(edges[0], edges[1]))\n",
    "    edges = set(map(lambda x: tuple(sorted(x)), edges))\n",
    "    return edges\n",
    "\n",
    "\n",
    "def calc_uuas(pred_distances, gold_distances):  \n",
    "    '''\n",
    "    Compute UUAS score for a pair of gold and predicted distances of a sentence.\n",
    "    '''\n",
    "    uuas_batch = []\n",
    "    for i in range(len(gold_distances)):\n",
    "        l = max(torch.nonzero(gold_distances[i] != -1, as_tuple=True)[0]) + 1\n",
    "        pred_mst = create_mst(pred_distances[i][:l, :l])\n",
    "        gold_mst = create_mst(gold_distances[i][:l, :l])\n",
    "        pred_edges = get_edges(pred_mst)\n",
    "        gold_edges = get_edges(gold_mst)\n",
    "        uuas_sent = len(pred_edges.intersection(gold_edges)) / len(gold_edges) if len(gold_edges) > 0 else -1\n",
    "        uuas_batch.append(uuas_sent)\n",
    "\n",
    "    return uuas_batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Define structural probe class & L1 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structural probe class (from John Hewitt)\n",
    "class StructuralProbe(nn.Module):\n",
    "    \"\"\" Computes squared L2 distance after projection by a matrix.\n",
    "    For a batch of sentences, computes all n^2 pairs of distances\n",
    "    for each sentence in the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_dim, rank, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.probe_rank = rank\n",
    "        self.model_dim = model_dim\n",
    "        \n",
    "        self.proj = nn.Parameter(data = torch.zeros(self.model_dim, self.probe_rank))\n",
    "        \n",
    "        nn.init.uniform_(self.proj, -0.05, 0.05)\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\" Computes all n^2 pairs of distances after projection\n",
    "        for each sentence in a batch.\n",
    "        Note that due to padding, some distances will be non-zero for pads.\n",
    "        Computes (B(h_i-h_j))^T(B(h_i-h_j)) for all i,j\n",
    "        Args:\n",
    "          batch: a batch of word representations of the shape\n",
    "            (batch_size, max_seq_len, representation_dim)\n",
    "        Returns:\n",
    "          A tensor of distances of shape (batch_size, max_seq_len, max_seq_len)\n",
    "        \"\"\"\n",
    "        transformed = torch.matmul(batch, self.proj)\n",
    "        \n",
    "        batchlen, seqlen, rank = transformed.size()\n",
    "        \n",
    "        transformed = transformed.unsqueeze(2)\n",
    "        transformed = transformed.expand(-1, -1, seqlen, -1)\n",
    "        transposed = transformed.transpose(1,2)\n",
    "        \n",
    "        diffs = transformed - transposed\n",
    "        \n",
    "        squared_diffs = diffs.pow(2)\n",
    "        squared_distances = torch.sum(squared_diffs, -1)\n",
    "\n",
    "        return squared_distances\n",
    "\n",
    "    \n",
    "class L1DistanceLoss(nn.Module):\n",
    "    \"\"\"Custom L1 loss for distance matrices.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, predictions, label_batch, length_batch):\n",
    "        \"\"\" Computes L1 loss on distance matrices.\n",
    "        Ignores all entries where label_batch=-1\n",
    "        Normalizes first within sentences (by dividing by the square of the sentence length)\n",
    "        and then across the batch.\n",
    "        Args:\n",
    "          predictions: A pytorch batch of predicted distances\n",
    "          label_batch: A pytorch batch of true distances\n",
    "          length_batch: A pytorch batch of sentence lengths\n",
    "        Returns:\n",
    "          A tuple of:\n",
    "            batch_loss: average loss in the batch\n",
    "            total_sents: number of sentences in the batch\n",
    "        \"\"\"\n",
    "        labels_1s = (label_batch != -1).float()\n",
    "        predictions_masked = predictions * labels_1s\n",
    "        labels_masked = label_batch * labels_1s\n",
    "        total_sents = torch.sum((length_batch != 0)).float()\n",
    "        squared_lengths = length_batch.pow(2).float()\n",
    "\n",
    "        if total_sents > 0:\n",
    "            loss_per_sent = torch.sum(torch.abs(predictions_masked - labels_masked), dim=(1,2))\n",
    "            normalized_loss_per_sent = loss_per_sent / squared_lengths\n",
    "            batch_loss = torch.sum(normalized_loss_per_sent) / total_sents\n",
    "        \n",
    "        else:\n",
    "            batch_loss = torch.tensor(0.0)\n",
    "        \n",
    "        return batch_loss, total_sents\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Create data for structural probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train set: 12543 | size of val set: 2002 | size of test set: 2077\n"
     ]
    }
   ],
   "source": [
    "def init_corpus(path, lm, tokenizer, run_mode, concat=False, cutoff=None):\n",
    "    \"\"\" Initialises the data of a corpus.\n",
    "    \n",
    "    Inputs:\n",
    "        path : str\n",
    "            Path to corpus location\n",
    "        lm: language model to encode sentences\n",
    "        tokenizer : tokenizer to tokenize sentences\n",
    "        run_mode: either 'default' or 'baseline-nc'; 'default' uses contextualized representations of the LM, 'baseline-nc' uses non-contextualized word embeddings \n",
    "        concat : bool, optional\n",
    "            Optional toggle to concatenate all the tensors\n",
    "            returned by `fetch_sen_reps`.\n",
    "        cutoff : int, optional\n",
    "            Optional integer to \"cutoff\" the data in the corpus.\n",
    "            This allows only a subset to be used, alleviating \n",
    "            memory usage.\n",
    "    Returns:\n",
    "        embs : torch.Tensor \n",
    "            embeddings tensor of shape (num_tokens_in_corpus, model_dim)\n",
    "        gold_distances : torch.Tensor \n",
    "            gold distances tensor of shape (num_sentences_in_corpus, max_sentence_length, max_sentence_length)\n",
    "    \"\"\"\n",
    "    # print('parsing corpus...')\n",
    "    corpus = parse_corpus(path)[:cutoff]\n",
    "    # print(f'fetching sentence representations using {lm_name} embeddings...')\n",
    "    embs = fetch_sen_reps(corpus, model=lm, tokenizer=tokenizer, run_mode=run_mode, concat=concat)    \n",
    "    # print('computing gold distances...')\n",
    "    gold_distances = create_gold_distances(corpus)\n",
    "    \n",
    "    return embs, gold_distances\n",
    "\n",
    "# create data for structural probe\n",
    "suffix = '' if run_mode == 'default' else '_nc' if run_mode == 'baseline-nc' else None\n",
    "train_data_str_path = f'{data_dir}/train_data_str{suffix}.pt'\n",
    "val_data_str_path = f'{data_dir}/val_data_str{suffix}.pt'\n",
    "test_data_str_path = f'{data_dir}/test_data_str{suffix}.pt'\n",
    "try:\n",
    "    train_data_str = torch.load(train_data_str_path)\n",
    "    val_data_str = torch.load(val_data_str_path)\n",
    "    test_data_str = torch.load(test_data_str_path)\n",
    "except FileNotFoundError:\n",
    "    print(f'creating data for structural probe using {lm_name} embeddings and {run_mode} run mode...')\n",
    "    train_x_str, train_y_str = init_corpus(train_path, lm=lm, tokenizer=tokenizer, run_mode=run_mode)\n",
    "    train_data_str = MyDataset(train_x_str, train_y_str)\n",
    "    val_x_str, val_y_str = init_corpus(val_path, lm=lm, tokenizer=tokenizer, run_mode=run_mode)\n",
    "    val_data_str = MyDataset(val_x_str, val_y_str)\n",
    "    test_x_str, test_y_str = init_corpus(test_path, lm=lm, tokenizer=tokenizer, run_mode=run_mode)\n",
    "    test_data_str = MyDataset(test_x_str, test_y_str)\n",
    "    torch.save(train_data_str, train_data_str_path)\n",
    "    torch.save(val_data_str, val_data_str_path)\n",
    "    torch.save(test_data_str, test_data_str_path)\n",
    "\n",
    "print(f'size of train set: {len(train_data_str)} | size of val set: {len(val_data_str)} | size of test set: {len(test_data_str)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Train & test structural probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate structural probe\n",
    "def evaluate_probe(model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    uuas = []\n",
    "    with torch.no_grad():\n",
    "      for x, gold_distances, length in dataloader:\n",
    "          preds = model(x)\n",
    "          loss += loss_fn(preds, gold_distances, length)[0]\n",
    "          uuas += calc_uuas(preds, gold_distances)\n",
    "    loss /= len(dataloader)\n",
    "    # take mean of uuas across batches where uuas != -1\n",
    "    uuas_avg = sum([x for x in uuas if x != -1])/len([x for x in uuas if x != -1])\n",
    "\n",
    "    return loss, uuas_avg, uuas\n",
    "\n",
    "def pad_collate_fn(batch):\n",
    "    max_length = max([len(x[1]) for x in batch])\n",
    "    out_labels = torch.full((len(batch), max_length, max_length), -1)\n",
    "    out_lengths = torch.zeros(len(batch))\n",
    "    for i, x in enumerate(batch):\n",
    "      out_labels[i, :x[1].shape[0], :x[1].shape[1]] = x[1]\n",
    "      out_lengths[i] = x[1].shape[0]\n",
    "      if len(x[0].shape) == 1:\n",
    "        batch[i] = (x[0].unsqueeze(0), x[1])\n",
    "    return torch.nn.utils.rnn.pad_sequence(list(map(lambda x: x[0].detach(), batch)), batch_first = True, padding_value=-1), out_labels, out_lengths\n",
    "\n",
    "def train_structural_probe(model, train_data, val_data, params, seed=42, print_every=10):\n",
    "    # create dataloaders\n",
    "    set_seed(seed)  # set seed for reproducibility\n",
    "    train_loader = DataLoader(train_data, batch_size=params.batch_size, shuffle=True, collate_fn=pad_collate_fn)\n",
    "    val_loader = DataLoader(val_data, batch_size=params.batch_size, shuffle=False, collate_fn=pad_collate_fn)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=params.lr)\n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1)\n",
    "    criterion =  L1DistanceLoss()\n",
    "    val_losses, val_uuas = [], []\n",
    "\n",
    "    # training/val loop\n",
    "    print(f'training structural probe with {lm_name} embeddings...')\n",
    "    for epoch in range(params.num_epochs):\n",
    "        # train\n",
    "        model.train()\n",
    "        for train_x, gold_distances, lengths in train_loader:\n",
    "            out = model(train_x)\n",
    "            loss = criterion(out, gold_distances, lengths)[0]\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            \n",
    "        # val\n",
    "        val_loss_epoch, val_uuas_epoch, _ = evaluate_probe(model, val_loader, criterion)\n",
    "        # scheduler.step(val_loss_epoch)\n",
    "        val_losses.append(val_loss_epoch)\n",
    "        val_uuas.append(val_uuas_epoch)\n",
    "        \n",
    "        if epoch % print_every == 0:\n",
    "            print(f'epoch: {epoch} | val loss: {val_loss_epoch:.3f} | val uuas: {val_uuas_epoch:.3f}')\n",
    "        \n",
    "        # early stopping\n",
    "        if epoch >= params.patience and val_loss_epoch >= val_losses[-params.patience]:\n",
    "            print(f'val loss did not improve for {params.patience} epochs, stopping training')\n",
    "            break\n",
    "        \n",
    "    return model, val_losses, val_uuas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded saved structural probe model using lstm embeddings and default run mode\n",
      "\n",
      "avg test uuas of structural pos probe using lstm embeddings and default run mode is 0.674, with 0.737 for short sentences and 0.579 for long sentences\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_accs_pos_sent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:20\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_accs_pos_sent' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train structural probe\n",
    "params = TrainingParams()\n",
    "str_model_path = f'{model_dir}/str_probe{suffix}.pt'\n",
    "try:\n",
    "    str_probe_model = torch.load(str_model_path)\n",
    "    print(f'loaded saved structural probe model using {lm_name} embeddings and {run_mode} run mode\\n')\n",
    "except FileNotFoundError:\n",
    "    str_probe_model = StructuralProbe(train_data_str[0][0].shape[1], rank=64)\n",
    "    str_probe_model, _, _ = train_structural_probe(str_probe_model, train_data_str, val_data_str, params)\n",
    "    torch.save(str_probe_model, str_model_path)\n",
    "\n",
    "# test\n",
    "test_loader_str = DataLoader(test_data_str, batch_size=params.batch_size, shuffle=False, collate_fn=pad_collate_fn)\n",
    "test_loss_str, test_uuas_str_avg, test_uuas_str   = evaluate_probe(str_probe_model, test_loader_str, L1DistanceLoss())\n",
    "test_uuas_str_short = np.mean([test_uuas_str[i] for i in idxs_short_sent_test if test_uuas_str[i] != -1])\n",
    "test_uuas_str_long = np.mean([test_uuas_str[i] for i in idxs_long_sent_test if test_uuas_str[i] != -1])  \n",
    "print(f'avg test uuas of structural pos probe using {lm_name} embeddings and {run_mode} run mode is {test_uuas_str_avg:.3f}, with {test_uuas_str_short:.3f} for short sentences and {test_uuas_str_long:.3f} for long sentences\\n')\n",
    "\n",
    "# compute correlation b/w PoS accuracy and uuas of structural probe on test set\n",
    "corr_pos_acc_uuas_test = spearmanr([test_accs_pos_sent[i] for i in range(len(test_accs_pos_sent)) if test_uuas_str[i] != -1], [x for x in test_uuas_str if x != -1])[0]\n",
    "print(f'correlation b/w PoS accuracy and uuas of structural probe per sentence on test set using {lm_name} embeddings and {run_mode} run mode: {corr_pos_acc_uuas_test:.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Linear baseline for structural probe\n",
    "We construct a simple linear baseline for the structural probe, which assumes that sentences are parsed in a left-to-right fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12543/12543 [00:00<00:00, 87673.89it/s]\n",
      "100%|██████████| 12543/12543 [01:07<00:00, 185.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg test uuas of structural linear probe using gpt2d embeddings is 0.443, with 0.415 for short sentences and 0.420 for long sentences\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_linear_distances(corpus):\n",
    "    '''Create a distance matrix assuming left-to-right parsing.'''\n",
    "    all_distances = []\n",
    "\n",
    "    for item in tqdm(corpus):\n",
    "        sen_len = len(item)\n",
    "        distances = torch.zeros((sen_len, sen_len))\n",
    "\n",
    "        # create a distance matrix assuming left-to-right parsing\n",
    "        positions = torch.arange(sen_len).unsqueeze(1)\n",
    "        distances = torch.abs(positions - positions.T)\n",
    "\n",
    "        all_distances.append(distances)\n",
    "\n",
    "    return all_distances\n",
    "\n",
    "test_corpus = parse_corpus(train_path)\n",
    "linear_distances_test = create_linear_distances(test_corpus)\n",
    "gold_distances_test = create_gold_distances(test_corpus)\n",
    "test_uuas_str_linear = calc_uuas(linear_distances_test, gold_distances_test)\n",
    "test_uuas_str_linear_avg = np.mean([x for x in test_uuas_str_linear if x != -1])\n",
    "test_uuas_str_linear_short = np.mean([test_uuas_str_linear[i] for i in idxs_short_sent_test if test_uuas_str_linear[i] != -1])\n",
    "test_uuas_str_linear_long = np.mean([test_uuas_str_linear[i] for i in idxs_long_sent_test if test_uuas_str_linear[i] != -1])  \n",
    "print(f'avg test uuas of structural linear probe using {lm_name} embeddings is {test_uuas_str_linear_avg:.3f}, with {test_uuas_str_linear_short:.3f} for short sentences and {test_uuas_str_linear_long:.3f} for long sentences\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Control tasks for structural probe\n",
    "We design a control task for the structural probe by generating random distances and MSTs, and training the structural probe on them. If the structural probe is actually probing the structural information, it should perform relatively worse on the control task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training structural probe with lstm embeddings...\n",
      "epoch: 0 | val loss: 0.735 | val uuas: 0.441\n",
      "epoch: 10 | val loss: 0.647 | val uuas: 0.534\n",
      "epoch: 20 | val loss: 0.642 | val uuas: 0.543\n",
      "val loss did not improve for 10 epochs, stopping training\n",
      "test uuas of structural control probe using lstm embeddings: 0.542, test loss: 0.627\n",
      "CPU times: user 46min 18s, sys: 12min 20s, total: 58min 38s\n",
      "Wall time: 3min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def create_control_distances(corpus_path, control_deps):\n",
    "    '''\n",
    "    Create control distances by generating a fake parse tree for each sentence.\n",
    "    '''\n",
    "    corpus = parse_corpus(corpus_path)\n",
    "    all_distances = []\n",
    "    for item in corpus:\n",
    "        n = len(item)\n",
    "        for i, word in enumerate(item):\n",
    "            if i == 0:\n",
    "                word['head'] = 0    # 1st word becomes root\n",
    "            elif i == n-1:\n",
    "                word['head'] = 1    # last word becomes child of root\n",
    "            elif word['form'] in control_deps:\n",
    "                word['head'] = 1 if control_deps[word['form']] == 'first' else n if control_deps[word['form']] == 'last' else i \n",
    "                # if word has attachment rule, apply it\n",
    "            else:\n",
    "                word['head'] = np.random.choice([1, i, n])  # otherwise, attach to either root, previous word or last word with equal probability\n",
    "                control_deps[word['form']] = 'first' if word['head'] == 1 else 'last' if word['head'] == n else 'prev'\n",
    "                # update attachment rule for this word\n",
    "        # generate fake parse tree\n",
    "        tree = item.to_tree()\n",
    "        tree = tokentree_to_ete(tree)\n",
    "        # print(tree, '\\n')\n",
    "        # create fake distance matrix\n",
    "        distances = torch.zeros(n,n)\n",
    "        for node1 in tree.traverse():\n",
    "            for node2 in tree.traverse():\n",
    "                no1 = int(node1.name) - 1\n",
    "                no2 = int(node2.name) - 1\n",
    "                distances[no1,no2] = node1.get_distance(node2)\n",
    "        all_distances.append(distances)\n",
    "        \n",
    "    return all_distances, control_deps\n",
    "        \n",
    "try:\n",
    "    train_data_str_control = torch.load(f'{data_dir}/train_data_str_control.pt')\n",
    "    val_data_str_control = torch.load(f'{data_dir}/val_data_str_control.pt')\n",
    "    test_data_str_control = torch.load(f'{data_dir}/test_data_str_control.pt')\n",
    "except FileNotFoundError:\n",
    "    # create control distances\n",
    "    print(f'creating data for structural control probe using {lm_name} embeddigs and {run_mode} run mode...')\n",
    "    # print('train')\n",
    "    control_deps = {}   # dict to store control dependencies\n",
    "    train_control_distances, control_deps = create_control_distances(train_path, control_deps)\n",
    "    # print('val')\n",
    "    val_control_distances, control_deps = create_control_distances(val_path, control_deps)\n",
    "    # print('test')\n",
    "    test_control_distances, control_deps = create_control_distances(test_path, control_deps)\n",
    "    train_data_str_control = MyDataset(train_data_str.x, train_control_distances)\n",
    "    val_data_str_control = MyDataset(val_data_str.x, val_control_distances)\n",
    "    test_data_str_control = MyDataset(test_data_str.x, test_control_distances)\n",
    "    torch.save(train_data_str_control, f'{data_dir}/train_data_str_control.pt')\n",
    "    torch.save(val_data_str_control, f'{data_dir}/val_data_str_control.pt')\n",
    "    torch.save(test_data_str_control, f'{data_dir}/test_data_str_control.pt')\n",
    "\n",
    "# train structural control probe\n",
    "try:\n",
    "    str_probe_control_model = torch.load(f'{model_dir}/str_probe_control.pt')\n",
    "    print(f'loaded saved structural control probe model using {lm_name} embeddings')\n",
    "except FileNotFoundError:\n",
    "    str_probe_control_model = StructuralProbe(train_data_str_control[0][0].shape[1], rank=64)\n",
    "    str_probe_control_model, _, _ = train_structural_probe(str_probe_control_model, train_data_str_control, val_data_str_control, params)\n",
    "    torch.save(str_probe_control_model, f'{model_dir}/str_probe_control.pt')\n",
    "\n",
    "# test\n",
    "test_loader_str_control = DataLoader(test_data_str_control, batch_size=params.batch_size, shuffle=False, collate_fn=pad_collate_fn)\n",
    "test_loss_str_control, test_uuas_str_control_avg, test_uuas_str_control = evaluate_probe(str_probe_control_model, test_loader_str_control, L1DistanceLoss())\n",
    "print(f'test uuas of structural control probe using {lm_name} embeddings: {test_uuas_str_control_avg:.3f}, test loss: {test_loss_str_control:.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print trees to LaTeX\n",
    "Code to print dependency tree plots in LaTeX like those of Figure 2 in the Structural Probing paper. \n",
    "**N.B.**: for the latex tikz tree the first token in a sentence has index 1 (instead of 0), so take that into account with the predicted and gold edges that you pass to the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tikz(predicted_edges, gold_edges, words):\n",
    "    \"\"\" Turns edge sets on word (nodes) into tikz dependency LaTeX.\n",
    "    Parameters\n",
    "    ----------\n",
    "    predicted_edges : Set[Tuple[int, int]]\n",
    "        Set (or list) of edge tuples, as predicted by your probe.\n",
    "    gold_edges : Set[Tuple[int, int]]\n",
    "        Set (or list) of gold edge tuples, as obtained from the treebank.\n",
    "    words : List[str]\n",
    "        List of strings representing the tokens in the sentence.\n",
    "    \"\"\"\n",
    "\n",
    "    string = \"\"\"\\\\begin{dependency}[hide label, edge unit distance=.5ex]\n",
    "    \\\\begin{deptext}[column sep=0.05cm]\n",
    "    \"\"\"\n",
    "\n",
    "    string += (\n",
    "        \"\\\\& \".join([x.replace(\"$\", \"\\$\").replace(\"&\", \"+\") for x in words])\n",
    "        + \" \\\\\\\\\\n\"\n",
    "    )\n",
    "    string += \"\\\\end{deptext}\" + \"\\n\"\n",
    "    for i_index, j_index in gold_edges:\n",
    "        string += \"\\\\depedge[-]{{{}}}{{{}}}{{{}}}\\n\".format(i_index, j_index, \".\")\n",
    "    for i_index, j_index in predicted_edges:\n",
    "        string += f\"\\\\depedge[-,edge style={{red!60!}}, edge below]{{{i_index}}}{{{j_index}}}{{.}}\\n\"\n",
    "    string += \"\\\\end{dependency}\\n\"\n",
    "    print(string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
